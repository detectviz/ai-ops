# SRE Platform é–‹ç™¼è€…å®Œæ•´æŒ‡å—

**ç›®æ¨™è®€è€…**: è»Ÿé«”å·¥ç¨‹å¸«ã€DevOps å·¥ç¨‹å¸«ã€å¹³å°é–‹ç™¼è€…  
**é›£åº¦ç­‰ç´š**: ä¸­ç´šåˆ°é«˜ç´š  
**é è¨ˆé–±è®€æ™‚é–“**: 45 åˆ†é˜

---

## ğŸ“‹ é–‹ç™¼è€…æŒ‡å—ç›®éŒ„

- [å°ˆæ¡ˆæˆç†Ÿåº¦](#å°ˆæ¡ˆæˆç†Ÿåº¦)
- [é–‹ç™¼ç’°å¢ƒè¨­ç½®](#é–‹ç™¼ç’°å¢ƒè¨­ç½®)
- [å°ˆæ¡ˆæ¶æ§‹æ·±å…¥](#å°ˆæ¡ˆæ¶æ§‹æ·±å…¥)
- [é–‹ç™¼å·¥ä½œæµç¨‹](#é–‹ç™¼å·¥ä½œæµç¨‹)
- [ä»£ç¢¼è¦ç¯„èˆ‡æœ€ä½³å¯¦è¸](#ä»£ç¢¼è¦ç¯„èˆ‡æœ€ä½³å¯¦è¸)
- [æ¸¬è©¦ç­–ç•¥èˆ‡å¯¦è¸](#æ¸¬è©¦ç­–ç•¥èˆ‡å¯¦è¸)
- [èª¿è©¦èˆ‡æ•…éšœæ’é™¤](#èª¿è©¦èˆ‡æ•…éšœæ’é™¤)


---

## å°ˆæ¡ˆæˆç†Ÿåº¦

> âš ï¸ **é‡è¦æç¤º**: æœ¬å°ˆæ¡ˆç›®å‰è™•æ–¼**æ—©æœŸé–‹ç™¼éšæ®µ**ã€‚

æœ¬é–‹ç™¼è€…æŒ‡å—æ—¨åœ¨æè¿°å°ˆæ¡ˆçš„**ç›®æ¨™æ¶æ§‹**èˆ‡**ç†æƒ³å·¥ä½œæµç¨‹**ã€‚é–‹ç™¼è€…æ‡‰æ³¨æ„ï¼Œç›®å‰çš„å¯¦ä½œèˆ‡æœ¬æ–‡ä»¶æè¿°ä¹‹é–“å¯èƒ½å­˜åœ¨ä»¥ä¸‹å·®ç•°ï¼š

- **åŠŸèƒ½å®Œæ•´æ€§**: è¨±å¤šæ ¸å¿ƒåŠŸèƒ½ï¼Œç‰¹åˆ¥æ˜¯ `SRE Assistant` çš„è¨ºæ–·èˆ‡ AI åˆ†æèƒ½åŠ›ï¼Œä»è™•æ–¼**éª¨æ¶æˆ–æ¨¡æ“¬ (mock) éšæ®µ**ã€‚
- **API ç‹€æ…‹**: API è¨­è¨ˆä»åœ¨æ¼”é€²ï¼Œå¯èƒ½æœƒå‡ºç¾èˆ‡ `openapi.yaml` å®šç¾©ä¸å®Œå…¨ä¸€è‡´çš„æƒ…æ³ã€‚
- **ç¨‹å¼ç¢¼å“è³ª**: éƒ¨åˆ†æ¨¡çµ„å¯èƒ½ä»åœ¨å¿«é€Ÿè¿­ä»£ï¼Œå°šæœªé”åˆ°ç”Ÿç”¢ç’°å¢ƒçš„ç©©å®šæ€§èˆ‡å“è³ªæ¨™æº–ã€‚

æˆ‘å€‘é¼“å‹µé–‹ç™¼è€…å°‡æœ¬æ–‡ä»¶ä½œç‚ºé–‹ç™¼çš„**è—åœ–**èˆ‡**æ–¹å‘**ï¼Œä¸¦ç©æ¥µåƒèˆ‡ï¼Œå…±åŒå°‡ç†æƒ³è®Šç‚ºç¾å¯¦ã€‚

---

## é–‹ç™¼ç’°å¢ƒè¨­ç½®

### ğŸ› ï¸ å®Œæ•´é–‹ç™¼ç’°å¢ƒæ¶æ§‹

```mermaid
graph TB
    subgraph "ğŸ–¥ï¸ é–‹ç™¼æ©Ÿå™¨"
        A[é–‹ç™¼è€…å·¥ä½œç«™] --> B[Docker Desktop]
        A --> C[IDE/ç·¨è¼¯å™¨]
        A --> D[Git å®¢æˆ¶ç«¯]
    end
    
    subgraph "ğŸ³ æœ¬åœ°å®¹å™¨ç’°å¢ƒ"
        E[PostgreSQL] --> F[Redis]
        F --> G[Keycloak]
        G --> H[VictoriaMetrics]
        H --> I[Grafana]
        I --> J[ChromaDB]
    end
    
    subgraph "ğŸš€ é–‹ç™¼æœå‹™"
        K[Control Plane:8081] --> L[SRE Assistant:8000]
        L --> M[Hot Reload]
        M --> N[Live Debugging]
    end
    
    A --> E
    K --> E
    L --> E
```

### ğŸ”§ ç³»çµ±è¦æ±‚è©³è§£

| çµ„ä»¶ | æœ€ä½è¦æ±‚ | æ¨è–¦é…ç½® | èªªæ˜ |
|------|----------|----------|------|
| **ä½œæ¥­ç³»çµ±** | Ubuntu 20.04+ | Ubuntu 22.04 LTS | æˆ–ç­‰æ•ˆçš„ Debian ç³»çµ± |
| **CPU** | 4 æ ¸å¿ƒ | 8 æ ¸å¿ƒ+ | æ”¯æ´ä½µç™¼é–‹ç™¼èˆ‡æ¸¬è©¦ |
| **è¨˜æ†¶é«”** | 8GB | 16GB+ | å®¹å™¨æœå‹™éœ€è¦å¤§é‡è¨˜æ†¶é«” |
| **ç£ç¢Ÿç©ºé–“** | 50GB | 100GB+ | åŒ…å« Docker æ˜ åƒèˆ‡æ•¸æ“š |
| **Go** | 1.21+ | 1.22+ | Control Plane é–‹ç™¼ |
| **Python** | 3.11+ | 3.12+ | SRE Assistant é–‹ç™¼ |
| **Node.js** | 18+ | 20+ | å‰ç«¯å·¥å…·èˆ‡æ¸¬è©¦ |
| **Docker** | 20.10+ | 24.0+ | å®¹å™¨åŒ–é–‹ç™¼ç’°å¢ƒ |

### âš¡ æ¥µé€Ÿç’°å¢ƒè¨­ç½®

#### æ–¹æ¡ˆä¸€ï¼šä¸€éµè‡ªå‹•åŒ–è¨­ç½® (æ¨è–¦)

```bash
# ğŸš€ è¶…ç´šå¿«é€Ÿè¨­ç½®
git clone https://github.com/detectviz/sre-platform
cd sre-platform

# ä¸€éµå®‰è£æ‰€æœ‰ä¾è³´å’Œæœå‹™
make setup-dev

# é©—è­‰å®‰è£
make verify

# å•Ÿå‹•é–‹ç™¼æ¨¡å¼
make dev
```

#### æ–¹æ¡ˆäºŒï¼šæ‰‹å‹•åˆ†æ­¥é©Ÿè¨­ç½®

```bash
# 1ï¸âƒ£ å®‰è£ç³»çµ±ä¾è³´
sudo apt update && sudo apt install -y \
    git curl wget build-essential \
    docker.io docker-compose \
    postgresql-client redis-tools

# 2ï¸âƒ£ å®‰è£ Go
wget https://golang.org/dl/go1.22.0.linux-amd64.tar.gz
sudo tar -C /usr/local -xzf go1.22.0.linux-amd64.tar.gz
echo 'export PATH=$PATH:/usr/local/go/bin' >> ~/.bashrc

# 3ï¸âƒ£ å®‰è£ Python & Poetry
curl -sSL https://install.python-poetry.org | python3 -
echo 'export PATH="$HOME/.local/bin:$PATH"' >> ~/.bashrc

# 4ï¸âƒ£ è¨­ç½®å°ˆæ¡ˆ
git clone https://github.com/detectviz/sre-platform
cd sre-platform

# 5ï¸âƒ£ å®‰è£å°ˆæ¡ˆä¾è³´
make install-deps

# 6ï¸âƒ£ å•Ÿå‹•åŸºç¤æœå‹™
make start-services

# 7ï¸âƒ£ é©—è­‰ç’°å¢ƒ
make verify
```

### ğŸ³ Docker é–‹ç™¼ç’°å¢ƒ (æ›¿ä»£æ–¹æ¡ˆ)

å°æ–¼å¸Œæœ›å®Œå…¨å®¹å™¨åŒ–é–‹ç™¼çš„é–‹ç™¼è€…ï¼š

```yaml
# docker-compose.dev.yml
version: '3.8'
services:
  control-plane-dev:
    build:
      context: ./services/control-plane
      dockerfile: Dockerfile.dev
    ports:
      - "8081:8081"
    volumes:
      - ./services/control-plane:/app
      - go-modules:/go/pkg/mod
    environment:
      - GO_ENV=development
      - HOT_RELOAD=true
    depends_on:
      - postgres
      - redis
      - keycloak

  sre-assistant-dev:
    build:
      context: ./services/sre-assistant  
      dockerfile: Dockerfile.dev
    ports:
      - "8000:8000"
    volumes:
      - ./services/sre-assistant:/app
      - poetry-cache:/root/.cache/pypoetry
    environment:
      - PYTHON_ENV=development
      - DEBUG=true
      - HOT_RELOAD=true
    depends_on:
      - postgres
      - chromadb

volumes:
  go-modules:
  poetry-cache:
```

```bash
# å•Ÿå‹• Docker é–‹ç™¼ç’°å¢ƒ
docker-compose -f docker-compose.dev.yml up -d

# é€²å…¥å®¹å™¨é€²è¡Œé–‹ç™¼
docker exec -it sre-platform_control-plane-dev_1 bash
docker exec -it sre-platform_sre-assistant-dev_1 bash
```

### ğŸ” ç’°å¢ƒé©—è­‰èˆ‡æ•…éšœæ’é™¤

#### å®Œæ•´é©—è­‰è…³æœ¬

```bash
#!/bin/bash
# verify_dev_environment.sh

echo "ğŸ” SRE Platform é–‹ç™¼ç’°å¢ƒé©—è­‰"
echo "=============================="

# æª¢æŸ¥åŸºæœ¬å·¥å…·
echo -n "ğŸ“¦ æª¢æŸ¥ Go ç‰ˆæœ¬... "
if go version >/dev/null 2>&1; then
    echo "âœ… $(go version)"
else
    echo "âŒ Go æœªå®‰è£æˆ–ç‰ˆæœ¬éèˆŠ"
    exit 1
fi

echo -n "ğŸ æª¢æŸ¥ Python ç‰ˆæœ¬... "
if python3 --version >/dev/null 2>&1; then
    echo "âœ… $(python3 --version)"
else
    echo "âŒ Python æœªå®‰è£æˆ–ç‰ˆæœ¬éèˆŠ"
    exit 1
fi

echo -n "ğŸ“ æª¢æŸ¥ Poetry... "
if poetry --version >/dev/null 2>&1; then
    echo "âœ… $(poetry --version)"
else
    echo "âŒ Poetry æœªå®‰è£"
    exit 1
fi

# æª¢æŸ¥æœå‹™é€£é€šæ€§
services=(
    "PostgreSQL:5432"
    "Redis:6379" 
    "Keycloak:8080"
    "VictoriaMetrics:8428"
    "Grafana:3000"
)

for service in "${services[@]}"; do
    name=$(echo $service | cut -d: -f1)
    port=$(echo $service | cut -d: -f2)
    echo -n "ğŸ”Œ æª¢æŸ¥ $name é€£æ¥... "
    
    if nc -z localhost $port >/dev/null 2>&1; then
        echo "âœ… é€£æ¥æˆåŠŸ"
    else
        echo "âŒ é€£æ¥å¤±æ•— (ç«¯å£ $port)"
    fi
done

# æª¢æŸ¥ API å¥åº·ç‹€æ…‹
echo -n "ğŸ¥ æª¢æŸ¥ Control Plane å¥åº·ç‹€æ…‹... "
if curl -f http://localhost:8081/health >/dev/null 2>&1; then
    echo "âœ… å¥åº·"
else
    echo "âŒ ä¸å¥åº·æˆ–æœªå•Ÿå‹•"
fi

if curl -f http://localhost:8000/health >/dev/null 2>&1; then
    echo "âœ… å¥åº·"
else
    echo "âŒ ä¸å¥åº·æˆ–æœªå•Ÿå‹•"
fi

echo ""
echo "ğŸ‰ ç’°å¢ƒé©—è­‰å®Œæˆï¼å¦‚æœ‰å•é¡Œè«‹æŸ¥çœ‹ä¸Šæ–¹çš„éŒ¯èª¤è¨Šæ¯ã€‚"
```
    
#### ç•°æ­¥ç·¨ç¨‹æœ€ä½³å¯¦è¸

```python
# src/sre_assistant/tools/base.py
import asyncio
import logging
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional, List
from contextlib import asynccontextmanager
import aiohttp
from ..contracts import ToolResult, ToolError

logger = logging.getLogger(__name__)

class AsyncBaseTool(ABC):
    """ç•°æ­¥å·¥å…·çš„åŸºç¤é¡åˆ¥
    
    æä¾›çµ±ä¸€çš„ç•°æ­¥å·¥å…·ä»‹é¢ï¼ŒåŒ…å«é‡è©¦ã€è¶…æ™‚ã€éŒ¯èª¤è™•ç†ç­‰é€šç”¨åŠŸèƒ½
    """
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.timeout = config.get('timeout_seconds', 30)
        self.retry_count = config.get('retry_count', 3)
        self.retry_delay = config.get('retry_delay', 1)
        self.session: Optional[aiohttp.ClientSession] = None
        
    async def __aenter__(self):
        """ç•°æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€²å…¥"""
        await self.initialize()
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ç•°æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€€å‡º"""
        await self.cleanup()
        
    async def initialize(self) -> None:
        """åˆå§‹åŒ–å·¥å…·è³‡æº"""
        if self.session is None:
            timeout = aiohttp.ClientTimeout(total=self.timeout)
            self.session = aiohttp.ClientSession(timeout=timeout)
            
    async def cleanup(self) -> None:
        """æ¸…ç†å·¥å…·è³‡æº"""
        if self.session and not self.session.closed:
            await self.session.close()
            self.session = None
            
    @abstractmethod
    async def execute(self, context: Dict[str, Any]) -> ToolResult:
        """åŸ·è¡Œå·¥å…·çš„ä¸»è¦é‚è¼¯
        
        Args:
            context: åŸ·è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            ToolResult: åŸ·è¡Œçµæœ
        """
        pass
        
    @abstractmethod
    def validate_context(self, context: Dict[str, Any]) -> bool:
        """é©—è­‰åŸ·è¡Œä¸Šä¸‹æ–‡
        
        Args:
            context: åŸ·è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            bool: ä¸Šä¸‹æ–‡æ˜¯å¦æœ‰æ•ˆ
        """
        pass
        
    async def execute_with_retry(self, context: Dict[str, Any]) -> ToolResult:
        """å¸¶é‡è©¦æ©Ÿåˆ¶çš„åŸ·è¡ŒåŒ…è£
        
        å¯¦ç¾æŒ‡æ•¸é€€é¿é‡è©¦ç­–ç•¥ï¼Œè‡ªå‹•è™•ç†æš«æ™‚æ€§éŒ¯èª¤
        
        Args:
            context: åŸ·è¡Œä¸Šä¸‹æ–‡
            
        Returns:
            ToolResult: åŸ·è¡Œçµæœ
        """
        if not self.validate_context(context):
            return ToolResult(
                success=False,
                error=ToolError(
                    code="INVALID_CONTEXT",
                    message="Context validation failed"
                )
            )
            
        last_error = None
        
        for attempt in range(self.retry_count):
            try:
                logger.debug(f"åŸ·è¡Œå·¥å…· {self.__class__.__name__}, å˜—è©¦ {attempt + 1}/{self.retry_count}")
                result = await self.execute(context)
                
                if result.success:
                    return result
                    
                # å¦‚æœæ˜¯éé‡è©¦æ€§éŒ¯èª¤ï¼Œç›´æ¥è¿”å›
                if result.error and not self._is_retryable_error(result.error):
                    return result
                    
                last_error = result.error
                
            except asyncio.TimeoutError:
                last_error = ToolError(
                    code="TIMEOUT_ERROR",
                    message=f"Tool execution timed out after {self.timeout} seconds"
                )
            except Exception as e:
                last_error = ToolError(
                    code="EXECUTION_ERROR", 
                    message=f"Unexpected error: {str(e)}"
                )
                logger.exception(f"å·¥å…·åŸ·è¡Œå‡ºç¾æœªé æœŸéŒ¯èª¤: {e}")
                
            # å¦‚æœä¸æ˜¯æœ€å¾Œä¸€æ¬¡å˜—è©¦ï¼Œç­‰å¾…å¾Œé‡è©¦
            if attempt < self.retry_count - 1:
                delay = self.retry_delay * (2 ** attempt)  # æŒ‡æ•¸é€€é¿
                logger.debug(f"å·¥å…·åŸ·è¡Œå¤±æ•—ï¼Œ{delay} ç§’å¾Œé‡è©¦...")
                await asyncio.sleep(delay)
                
        return ToolResult(
            success=False,
            error=last_error or ToolError(
                code="UNKNOWN_ERROR",
                message="Tool execution failed with unknown error"
            )
        )
        
    def _is_retryable_error(self, error: ToolError) -> bool:
        """åˆ¤æ–·éŒ¯èª¤æ˜¯å¦å¯é‡è©¦
        
        Args:
            error: éŒ¯èª¤å°è±¡
            
        Returns:
            bool: æ˜¯å¦å¯é‡è©¦
        """
        retryable_codes = {
            'TIMEOUT_ERROR',
            'CONNECTION_ERROR',
            'SERVICE_UNAVAILABLE',
            'RATE_LIMITED',
            'TEMPORARY_ERROR'
        }
        return error.code in retryable_codes
        
    @asynccontextmanager
    async def http_request(self, method: str, url: str, **kwargs):
        """HTTP è«‹æ±‚çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        
        æä¾›çµ±ä¸€çš„ HTTP è«‹æ±‚è™•ç†ï¼ŒåŒ…å«éŒ¯èª¤è™•ç†å’Œæ—¥èªŒè¨˜éŒ„
        
        Args:
            method: HTTP æ–¹æ³•
            url: è«‹æ±‚ URL
            **kwargs: é¡å¤–çš„è«‹æ±‚åƒæ•¸
            
        Yields:
            aiohttp.ClientResponse: HTTP éŸ¿æ‡‰å°è±¡
        """
        if not self.session:
            await self.initialize()
            
        try:
            logger.debug(f"ç™¼é€ {method} è«‹æ±‚åˆ° {url}")
            async with self.session.request(method, url, **kwargs) as response:
                yield response
        except aiohttp.ClientTimeout:
            raise asyncio.TimeoutError(f"HTTP request to {url} timed out")
        except aiohttp.ClientError as e:
            raise Exception(f"HTTP request failed: {e}")
```

#### æ¸¬è©¦ç·¨å¯«è¦ç¯„

```python
# tests/unit/test_prometheus_tool.py
import pytest
import asyncio
from unittest.mock import AsyncMock, patch, MagicMock
from aiohttp import ClientSession, ClientTimeout
import aioresponses

from src.sre_assistant.tools.prometheus_tool import PrometheusQueryTool
from src.sre_assistant.contracts import ToolResult

class TestPrometheusQueryTool:
    """PrometheusQueryTool çš„å–®å…ƒæ¸¬è©¦
    
    æ¸¬è©¦è¦†è“‹æ­£å¸¸æµç¨‹ã€éŒ¯èª¤è™•ç†ã€é‚Šç•Œæ¢ä»¶ç­‰å„ç¨®å ´æ™¯
    """
    
    @pytest.fixture
    def tool_config(self):
        """æ¸¬è©¦ç”¨çš„å·¥å…·é…ç½®"""
        return {
            'prometheus': {
                'base_url': 'http://localhost:9090',
                'step': '1m'
            },
            'timeout_seconds': 10,
            'retry_count': 2
        }
    
    @pytest.fixture
    def prometheus_tool(self, tool_config):
        """PrometheusQueryTool å¯¦ä¾‹"""
        return PrometheusQueryTool(tool_config)
    
    @pytest.fixture
    def valid_context(self):
        """æœ‰æ•ˆçš„åŸ·è¡Œä¸Šä¸‹æ–‡"""
        return {
            'service_name': 'test-service',
            'time_range': {
                'start': '2025-09-05T12:00:00Z',
                'end': '2025-09-05T13:00:00Z'
            }
        }
    
    @pytest.mark.asyncio
    async def test_successful_execution(self, prometheus_tool, valid_context):
        """æ¸¬è©¦æˆåŠŸåŸ·è¡Œçš„æƒ…æ³"""
        # æ¨¡æ“¬ Prometheus API éŸ¿æ‡‰
        mock_response_data = {
            'status': 'success',
            'data': {
                'result': [{
                    'metric': {'__name__': 'http_request_duration_seconds'},
                    'values': [
                        ['1693910400', '0.1'],
                        ['1693910460', '0.12'],
                        ['1693910520', '0.15']
                    ]
                }]
            }
        }
        
        with aioresponses.aioresponses() as m:
            # æ¨¡æ“¬å¤šå€‹æŒ‡æ¨™æŸ¥è©¢
            for i in range(11):  # é»ƒé‡‘æŒ‡æ¨™æ•¸é‡
                m.get(
                    'http://localhost:9090/api/v1/query_range',
                    payload=mock_response_data
                )
            
            result = await prometheus_tool.execute_with_retry(valid_context)
            
            assert result.success is True
            assert 'service_name' in result.data
            assert result.data['service_name'] == 'test-service'
            assert 'metrics' in result.data
            assert len(result.data['metrics']) > 0
    
    @pytest.mark.asyncio
    async def test_invalid_context(self, prometheus_tool):
        """æ¸¬è©¦ç„¡æ•ˆä¸Šä¸‹æ–‡çš„è™•ç†"""
        invalid_context = {
            # ç¼ºå°‘ service_name
            'time_range': {
                'start': '2025-09-05T12:00:00Z',
                'end': '2025-09-05T13:00:00Z'
            }
        }
        
        result = await prometheus_tool.execute_with_retry(invalid_context)
        
        assert result.success is False
        assert result.error.code == "INVALID_CONTEXT"
    
    @pytest.mark.asyncio
    async def test_prometheus_api_error(self, prometheus_tool, valid_context):
        """æ¸¬è©¦ Prometheus API éŒ¯èª¤çš„è™•ç†"""
        with aioresponses.aioresponses() as m:
            m.get(
                'http://localhost:9090/api/v1/query_range',
                status=500,
                payload={'error': 'Internal server error'}
            )
            
            result = await prometheus_tool.execute_with_retry(valid_context)
            
            assert result.success is False
            # ç”±æ–¼é‡è©¦æ©Ÿåˆ¶ï¼Œæ‡‰è©²å˜—è©¦å¤šæ¬¡
    
    @pytest.mark.asyncio
    async def test_timeout_handling(self, prometheus_tool, valid_context):
        """æ¸¬è©¦è¶…æ™‚è™•ç†"""
        with aioresponses.aioresponses() as m:
            # æ¨¡æ“¬è¶…æ™‚éŸ¿æ‡‰
            async def slow_response(url, **kwargs):
                await asyncio.sleep(15)  # è¶…éé…ç½®çš„ 10 ç§’è¶…æ™‚
                return {'status': 'success', 'data': {'result': []}}
            
            m.get(
                'http://localhost:9090/api/v1/query_range',
                callback=slow_response
            )
            
            result = await prometheus_tool.execute_with_retry(valid_context)
            
            assert result.success is False
            assert "timeout" in result.error.message.lower()
    
    @pytest.mark.asyncio
    async def test_resource_cleanup(self, prometheus_tool):
        """æ¸¬è©¦è³‡æºæ¸…ç†"""
        # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        async with prometheus_tool:
            assert prometheus_tool.session is not None
            assert not prometheus_tool.session.closed
            
        # é›¢é–‹ä¸Šä¸‹æ–‡å¾Œæ‡‰è©²æ¸…ç†è³‡æº
        assert prometheus_tool.session is None or prometheus_tool.session.closed
    
    def test_metrics_health_assessment(self, prometheus_tool):
        """æ¸¬è©¦æŒ‡æ¨™å¥åº·è©•ä¼°é‚è¼¯"""
        # æ¸¬è©¦ä¸åŒçš„æŒ‡æ¨™å€¼å°æ‡‰çš„å¥åº·ç‹€æ…‹
        test_cases = [
            ('error_rate', 0.005, 'healthy'),    # 0.5% éŒ¯èª¤ç‡
            ('error_rate', 0.02, 'warning'),     # 2% éŒ¯èª¤ç‡
            ('error_rate', 0.08, 'critical'),    # 8% éŒ¯èª¤ç‡
            ('latency_p99', 0.3, 'healthy'),     # 300ms
            ('latency_p99', 0.8, 'warning'),     # 800ms
            ('latency_p99', 2.5, 'critical'),    # 2.5s
        ]
        
        for metric_name, value, expected_status in test_cases:
            data = {
                'statistics': {'current': value}
            }
            status = prometheus_tool._assess_metric_health(metric_name, data)
            assert status == expected_status, f"æŒ‡æ¨™ {metric_name} å€¼ {value} æ‡‰è©²æ˜¯ {expected_status}ï¼Œä½†å¾—åˆ° {status}"
    
    def test_trend_calculation(self, prometheus_tool):
        """æ¸¬è©¦è¶¨å‹¢è¨ˆç®—é‚è¼¯"""
        # æ¸¬è©¦ä¸åŒè¶¨å‹¢çš„æ•¸æ“š
        test_cases = [
            ([1.0, 1.1, 1.2, 1.3, 1.4], 'increasing'),  # æŒçºŒä¸Šå‡
            ([1.4, 1.3, 1.2, 1.1, 1.0], 'decreasing'),  # æŒçºŒä¸‹é™
            ([1.0, 1.0, 1.0, 1.0, 1.0], 'stable'),      # ä¿æŒç©©å®š
            ([1.0, 1.2, 0.9, 1.1, 1.0], 'stable'),      # å°å¹…æ³¢å‹•
        ]
        
        for values, expected_trend in test_cases:
            trend = prometheus_tool._calculate_trend(values)
            assert trend == expected_trend, f"æ•¸æ“š {values} çš„è¶¨å‹¢æ‡‰è©²æ˜¯ {expected_trend}ï¼Œä½†å¾—åˆ° {trend}"

# tests/integration/test_sre_workflow.py
import pytest
import asyncio
from unittest.mock import AsyncMock, patch
import json

from src.sre_assistant.workflow import DiagnosticWorkflow
from src.sre_assistant.contracts import SRERequest, SeverityLevel

class TestSREWorkflowIntegration:
    """SRE å·¥ä½œæµç¨‹çš„æ•´åˆæ¸¬è©¦
    
    æ¸¬è©¦å¤šå€‹å·¥å…·å”åŒå·¥ä½œçš„å®Œæ•´æµç¨‹
    """
    
    @pytest.fixture
    def workflow_config(self):
        """å·¥ä½œæµç¨‹é…ç½®"""
        return {
            'prometheus': {
                'base_url': 'http://localhost:9090'
            },
            'loki': {
                'base_url': 'http://localhost:3100'
            },
            'control_plane': {
                'base_url': 'http://localhost:8081'
            },
            'parallel_execution': True,
            'workflow_timeout': 60
        }
    
    @pytest.fixture
    def diagnostic_workflow(self, workflow_config):
        """DiagnosticWorkflow å¯¦ä¾‹"""
        return DiagnosticWorkflow(workflow_config)
    
    @pytest.fixture
    def deployment_request(self):
        """éƒ¨ç½²è¨ºæ–·è«‹æ±‚"""
        return SRERequest(
            incident_id="deploy-test-001",
            severity=SeverityLevel.P2,
            input="è¨ºæ–·éƒ¨ç½²å•é¡Œ",
            affected_services=["test-service"],
            context={
                "type": "deployment_diagnosis",
                "deployment_id": "deploy-xyz-123",
                "service_name": "test-service",
                "namespace": "production"
            }
        )
    
    @pytest.mark.asyncio
    async def test_end_to_end_deployment_diagnosis(self, diagnostic_workflow, deployment_request):
        """æ¸¬è©¦ç«¯åˆ°ç«¯çš„éƒ¨ç½²è¨ºæ–·æµç¨‹"""
        # æ¨¡æ“¬å„å·¥å…·çš„è¿”å›çµæœ
        with patch.object(diagnostic_workflow, '_collect_metrics') as mock_metrics, \
             patch.object(diagnostic_workflow, '_collect_logs') as mock_logs, \
             patch.object(diagnostic_workflow, '_collect_audit_logs') as mock_audit, \
             patch.object(diagnostic_workflow, '_collect_kubernetes_status') as mock_k8s:
            
            # è¨­å®šæ¨¡æ“¬è¿”å›å€¼
            mock_metrics.return_value = self._create_mock_metrics_result()
            mock_logs.return_value = self._create_mock_logs_result()
            mock_audit.return_value = self._create_mock_audit_result()
            mock_k8s.return_value = self._create_mock_k8s_result()
            
            # åŸ·è¡Œå·¥ä½œæµç¨‹
            result = await diagnostic_workflow.execute_deployment_diagnosis(deployment_request)
            
            # é©—è­‰çµæœçµæ§‹
            assert result['status'] == 'COMPLETED'
            assert 'deployment_summary' in result
            assert 'analysis' in result
            assert 'recommendations' in result
            assert 'confidence_score' in result
            assert 'metadata' in result
            
            # é©—è­‰å„å·¥å…·éƒ½è¢«èª¿ç”¨
            mock_metrics.assert_called_once()
            mock_logs.assert_called_once()
            mock_audit.assert_called_once()
            mock_k8s.assert_called_once()
    
    @pytest.mark.asyncio
    async def test_parallel_vs_sequential_execution(self, workflow_config, deployment_request):
        """æ¸¬è©¦ä¸¦è¡Œå’Œé †åºåŸ·è¡Œçš„æ€§èƒ½å·®ç•°"""
        # ä¸¦è¡ŒåŸ·è¡Œ
        parallel_workflow = DiagnosticWorkflow({
            **workflow_config,
            'parallel_execution': True
        })
        
        # é †åºåŸ·è¡Œ
        sequential_workflow = DiagnosticWorkflow({
            **workflow_config,
            'parallel_execution': False
        })
        
        # æ¨¡æ“¬å·¥å…·åŸ·è¡Œæ™‚é–“
        async def slow_tool_execution(*args, **kwargs):
            await asyncio.sleep(0.1)  # æ¨¡æ“¬ 100ms åŸ·è¡Œæ™‚é–“
            return self._create_mock_metrics_result()
        
        with patch.multiple(
            parallel_workflow,
            _collect_metrics=slow_tool_execution,
            _collect_logs=slow_tool_execution,
            _collect_audit_logs=slow_tool_execution,
            _collect_kubernetes_status=slow_tool_execution
        ), patch.multiple(
            sequential_workflow,
            _collect_metrics=slow_tool_execution,
            _collect_logs=slow_tool_execution,
            _collect_audit_logs=slow_tool_execution,
            _collect_kubernetes_status=slow_tool_execution
        ):
            
            # æ¸¬é‡åŸ·è¡Œæ™‚é–“
            import time
            
            start_time = time.time()
            parallel_result = await parallel_workflow.execute_deployment_diagnosis(deployment_request)
            parallel_time = time.time() - start_time
            
            start_time = time.time()
            sequential_result = await sequential_workflow.execute_deployment_diagnosis(deployment_request)
            sequential_time = time.time() - start_time
            
            # ä¸¦è¡ŒåŸ·è¡Œæ‡‰è©²æ˜é¡¯å¿«æ–¼é †åºåŸ·è¡Œ
            assert parallel_time < sequential_time * 0.8  # è‡³å°‘å¿« 20%
            
            # çµæœæ‡‰è©²ç›¸ä¼¼ï¼ˆé™¤äº†åŸ·è¡Œæ™‚é–“ï¼‰
            assert parallel_result['status'] == sequential_result['status']
    
    def _create_mock_metrics_result(self):
        """å‰µå»ºæ¨¡æ“¬çš„æŒ‡æ¨™æŸ¥è©¢çµæœ"""
        from src.sre_assistant.contracts import ToolResult
        
        return ToolResult(
            success=True,
            data={
                'service_name': 'test-service',
                'metrics': {
                    'latency_p99': {
                        'status': 'success',
                        'statistics': {
                            'current': 0.8,
                            'trend': 'increasing'
                        }
                    },
                    'error_rate': {
                        'status': 'success',
                        'statistics': {
                            'current': 0.02,
                            'trend': 'stable'
                        }
                    }
                },
                'summary': {
                    'healthy_metrics': 8,
                    'warning_metrics': 2,
                    'critical_metrics': 1,
                    'failed_metrics': 0
                }
            }
        )
    
    def _create_mock_logs_result(self):
        """å‰µå»ºæ¨¡æ“¬çš„æ—¥èªŒæŸ¥è©¢çµæœ"""
        from src.sre_assistant.contracts import ToolResult
        
        return ToolResult(
            success=True,
            data={
                'error_patterns': [
                    {
                        'pattern': 'Connection timeout',
                        'count': 45,
                        'severity': 'high'
                    }
                ],
                'log_summary': {
                    'total_logs': 1000,
                    'error_logs': 45,
                    'warning_logs': 123
                }
            }
        )
    
    def _create_mock_audit_result(self):
        """å‰µå»ºæ¨¡æ“¬çš„å¯©è¨ˆæ—¥èªŒçµæœ"""
        from src.sre_assistant.contracts import ToolResult
        
        return ToolResult(
            success=True,
            data={
                'recent_changes': [
                    {
                        'timestamp': '2025-09-05T12:00:00Z',
                        'event_type': 'DEPLOYMENT',
                        'author': 'admin@company.com',
                        'summary': 'Deployed test-service v2.1.0'
                    }
                ]
            }
        )
    
    def _create_mock_k8s_result(self):
        """å‰µå»ºæ¨¡æ“¬çš„ Kubernetes ç‹€æ…‹çµæœ"""
        from src.sre_assistant.contracts import ToolResult
        
        return ToolResult(
            success=True,
            data={
                'deployment_status': {
                    'desired_replicas': 3,
                    'current_replicas': 2,
                    'ready_replicas': 1
                },
                'pod_issues': [
                    {
                        'pod_name': 'test-service-abc123',
                        'status': 'ImagePullBackOff',
                        'message': 'Failed to pull image'
                    }
                ]
            }
        )
```

---

## å°ˆæ¡ˆæ¶æ§‹æ·±å…¥

### ğŸ—ï¸ Monorepo çµæ§‹è©³è§£

```
sre-platform/
â”œâ”€â”€ ğŸ“ services/                    # å¾®æœå‹™ç›®éŒ„
â”‚   â”œâ”€â”€ ğŸ¯ control-plane/           # Go å¾Œç«¯æœå‹™
â”‚   â”‚   â”œâ”€â”€ cmd/
â”‚   â”‚   â”‚   â””â”€â”€ server/             # æ‡‰ç”¨ç¨‹å¼å…¥å£é»
â”‚   â”‚   â”‚       â””â”€â”€ main.go         # ä¸»å‡½å¼
â”‚   â”‚   â”œâ”€â”€ internal/               # ç§æœ‰æ‡‰ç”¨ç¨‹å¼ç¢¼
â”‚   â”‚   â”‚   â”œâ”€â”€ api/                # API è™•ç†å™¨
â”‚   â”‚   â”‚   â”œâ”€â”€ auth/               # èªè­‰ä¸­é–“ä»¶
â”‚   â”‚   â”‚   â”œâ”€â”€ config/             # é…ç½®ç®¡ç†
â”‚   â”‚   â”‚   â”œâ”€â”€ database/           # è³‡æ–™åº«å±¤
â”‚   â”‚   â”‚   â”œâ”€â”€ handlers/           # HTTP è™•ç†å™¨
â”‚   â”‚   â”‚   â”œâ”€â”€ middleware/         # ä¸­é–“ä»¶
â”‚   â”‚   â”‚   â”œâ”€â”€ models/             # è³‡æ–™æ¨¡å‹
â”‚   â”‚   â”‚   â”œâ”€â”€ services/           # æ¥­å‹™é‚è¼¯
â”‚   â”‚   â”‚   â””â”€â”€ utils/              # å·¥å…·å‡½æ•¸
â”‚   â”‚   â”œâ”€â”€ templates/              # HTMX æ¨¡æ¿
â”‚   â”‚   â”œâ”€â”€ static/                 # éœæ…‹è³‡æº (CSS, JS, åœ–ç‰‡)
â”‚   â”‚   â”œâ”€â”€ tests/                  # æ¸¬è©¦æª”æ¡ˆ
â”‚   â”‚   â”œâ”€â”€ Dockerfile              # å®¹å™¨åŒ–é…ç½®
â”‚   â”‚   â”œâ”€â”€ go.mod                  # Go æ¨¡çµ„å®šç¾©
â”‚   â”‚   â””â”€â”€ go.sum                  # Go ä¾è³´é–å®š
â”‚   â””â”€â”€ ğŸ¤– sre-assistant/           # Python AI æœå‹™
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â””â”€â”€ sre_assistant/      # ä¸»è¦æ‡‰ç”¨ç¨‹å¼ç¢¼
â”‚       â”‚       â”œâ”€â”€ __init__.py
â”‚       â”‚       â”œâ”€â”€ main.py         # FastAPI æ‡‰ç”¨ç¨‹å¼å…¥å£
â”‚       â”‚       â”œâ”€â”€ contracts.py    # è³‡æ–™å¥‘ç´„èˆ‡æ¨¡å‹
â”‚       â”‚       â”œâ”€â”€ workflow.py     # å·¥ä½œæµç¨‹å”èª¿å™¨
â”‚       â”‚       â”œâ”€â”€ config/         # é…ç½®ç®¡ç†
â”‚       â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚       â”‚   â”œâ”€â”€ settings.py # è¨­å®šè¼‰å…¥
â”‚       â”‚       â”‚   â””â”€â”€ environments/ # ç’°å¢ƒç‰¹å®šé…ç½®
â”‚       â”‚       â””â”€â”€ tools/          # è¨ºæ–·å·¥å…·é›†
â”‚       â”‚           â”œâ”€â”€ __init__.py
â”‚       â”‚           â”œâ”€â”€ base.py     # åŸºç¤å·¥å…·é¡åˆ¥
â”‚       â”‚           â”œâ”€â”€ control_plane_tool.py
â”‚       â”‚           â”œâ”€â”€ prometheus_tool.py
â”‚       â”‚           â”œâ”€â”€ loki_tool.py
â”‚       â”‚           â””â”€â”€ kubernetes_tool.py
â”‚       â”œâ”€â”€ tests/                  # æ¸¬è©¦å¥—ä»¶
â”‚       â”‚   â”œâ”€â”€ unit/               # å–®å…ƒæ¸¬è©¦
â”‚       â”‚   â”œâ”€â”€ integration/        # æ•´åˆæ¸¬è©¦
â”‚       â”‚   â””â”€â”€ fixtures/           # æ¸¬è©¦è³‡æ–™
â”‚       â”œâ”€â”€ config/                 # é…ç½®æª”æ¡ˆ
â”‚       â”œâ”€â”€ pyproject.toml          # Python å°ˆæ¡ˆé…ç½®
â”‚       â”œâ”€â”€ poetry.lock             # ä¾è³´é–å®šæª”æ¡ˆ
â”‚       â””â”€â”€ Dockerfile              # å®¹å™¨åŒ–é…ç½®
â”œâ”€â”€ ğŸ“ pkg/                         # å…±äº«å¥—ä»¶
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ openapi.yaml            # API å¥‘ç´„è¦æ ¼ï¼ˆå”¯ä¸€çœŸå¯¦ä¾†æºï¼‰
â”‚   â”œâ”€â”€ utils/                      # å…±äº«å·¥å…·
â”‚   â””â”€â”€ models/                     # å…±äº«è³‡æ–™æ¨¡å‹
â”œâ”€â”€ ğŸ“ docs/                        # å°ˆæ¡ˆæ–‡ä»¶
â”‚   â”œâ”€â”€ ARCHITECTURE.md             # æ¶æ§‹è¨­è¨ˆæ–‡ä»¶
â”‚   â”œâ”€â”€ USER_GUIDE.md              # ä½¿ç”¨è€…æŒ‡å—
â”‚   â”œâ”€â”€ SRE_ASSISTANT.md           # SRE Assistant é–‹ç™¼æŒ‡å—
â”‚   â”œâ”€â”€ ROADMAP.md                 # é–‹ç™¼è·¯ç·šåœ–
â”‚   â””â”€â”€ api/                       # API æ–‡ä»¶
â”œâ”€â”€ ğŸ“ local/                       # æœ¬åœ°é–‹ç™¼å·¥å…·
â”‚   â”œâ”€â”€ setup_local_environment.sh # ç’°å¢ƒè¨­ç½®è…³æœ¬
â”‚   â”œâ”€â”€ verify_environment.sh      # ç’°å¢ƒé©—è­‰è…³æœ¬
â”‚   â””â”€â”€ docker-compose.dev.yml     # é–‹ç™¼ç”¨ Docker Compose
â”œâ”€â”€ ğŸ“ k8s/                         # Kubernetes éƒ¨ç½²é…ç½®
â”‚   â”œâ”€â”€ namespace.yaml
â”‚   â”œâ”€â”€ configmaps/
â”‚   â”œâ”€â”€ deployments/
â”‚   â””â”€â”€ services/
â”œâ”€â”€ ğŸ“ ci/                          # CI/CD é…ç½®
â”‚   â”œâ”€â”€ .github/
â”‚   â”‚   â””â”€â”€ workflows/              # GitHub Actions
â”‚   â”œâ”€â”€ Jenkinsfile                # Jenkins æµæ°´ç·š
â”‚   â””â”€â”€ gitlab-ci.yml              # GitLab CI
â”œâ”€â”€ ğŸ”§ Makefile                     # çµ±ä¸€é–‹ç™¼æŒ‡ä»¤
â”œâ”€â”€ ğŸ“‹ README.md                    # å°ˆæ¡ˆèªªæ˜
â”œâ”€â”€ ğŸ“„ LICENSE                      # é–‹æºè¨±å¯è­‰
â”œâ”€â”€ ğŸ¤– AGENT.md                     # AI ä»£ç†é–‹ç™¼æŒ‡å—
â””â”€â”€ .gitignore                      # Git å¿½ç•¥æª”æ¡ˆ
```

### ğŸ¯ Control Plane æ¶æ§‹æ·±åº¦åˆ†æ

#### åˆ†å±¤æ¶æ§‹è¨­è¨ˆ

```mermaid
graph TB
    subgraph "ğŸŒ Presentation Layer"
        A[HTMX Templates] --> B[Static Assets]
        A --> C[Alpine.js Components]
        A --> D[Tailwind CSS]
    end
    
    subgraph "ğŸ® Application Layer"
        E[HTTP Handlers] --> F[Middleware Stack]
        F --> G[Request Validation]
        F --> H[Authentication] 
        F --> I[Authorization]
        F --> J[Logging & Metrics]
    end
    
    subgraph "ğŸ’¼ Business Layer"
        K[Resource Service] --> L[User Service]
        L --> M[Alert Service]
        M --> N[Audit Service]
        N --> O[Workflow Engine]
    end
    
    subgraph "ğŸ”Œ Integration Layer"
        P[SRE Assistant Client] --> Q[Keycloak Client]
        Q --> R[Grafana Client]
        R --> S[Metrics Collector]
    end
    
    subgraph "ğŸ’¾ Data Layer"
        T[(PostgreSQL)] --> U[Repository Pattern]
        U --> V[Entity Models]
        V --> W[Migrations]
    end
    
    A --> E
    E --> K
    K --> P
    P --> T
```

#### é—œéµè¨­è¨ˆæ¨¡å¼

**1. Repository Patternï¼ˆå€‰åº«æ¨¡å¼ï¼‰**
```go
// internal/models/resource.go
type Resource struct {
    ID        int       `json:"id" db:"id"`
    Name      string    `json:"name" db:"name"`
    Type      string    `json:"type" db:"type"`
    IPAddress string    `json:"ip_address" db:"ip_address"`
    Status    string    `json:"status" db:"status"`
    TeamID    int       `json:"team_id" db:"team_id"`
    Metadata  JSON      `json:"metadata" db:"metadata"`
    CreatedAt time.Time `json:"created_at" db:"created_at"`
    UpdatedAt time.Time `json:"updated_at" db:"updated_at"`
}

// internal/database/resource_repository.go
type ResourceRepository interface {
    GetAll(ctx context.Context, filters ResourceFilters) ([]Resource, error)
    GetByID(ctx context.Context, id int) (*Resource, error)
    Create(ctx context.Context, resource *Resource) error
    Update(ctx context.Context, resource *Resource) error
    Delete(ctx context.Context, id int) error
    BatchDelete(ctx context.Context, ids []int) error
}

type resourceRepository struct {
    db *sqlx.DB
}

func (r *resourceRepository) GetAll(ctx context.Context, filters ResourceFilters) ([]Resource, error) {
    query := `
        SELECT id, name, type, ip_address, status, team_id, metadata, created_at, updated_at
        FROM resources 
        WHERE ($1::text IS NULL OR type = $1)
        AND ($2::text IS NULL OR status = $2)
        AND ($3::int IS NULL OR team_id = $3)
        ORDER BY updated_at DESC
        LIMIT $4 OFFSET $5
    `
    
    var resources []Resource
    err := r.db.SelectContext(ctx, &resources, query, 
        filters.Type, filters.Status, filters.TeamID, 
        filters.Limit, filters.Offset)
    
    return resources, err
}
```

**2. Service Layer Patternï¼ˆæœå‹™å±¤æ¨¡å¼ï¼‰**
```go
// internal/services/resource_service.go
type ResourceService struct {
    repo           ResourceRepository
    auditService   *AuditService
    metricsCollector *MetricsCollector
}

func (s *ResourceService) CreateResource(ctx context.Context, req CreateResourceRequest) (*Resource, error) {
    // 1. é©—è­‰è¼¸å…¥
    if err := s.validateCreateRequest(req); err != nil {
        return nil, fmt.Errorf("validation failed: %w", err)
    }
    
    // 2. æª¢æŸ¥é‡è¤‡
    existing, err := s.repo.GetByIPAddress(ctx, req.IPAddress)
    if err != nil && !errors.Is(err, ErrResourceNotFound) {
        return nil, fmt.Errorf("failed to check existing resource: %w", err)
    }
    if existing != nil {
        return nil, ErrResourceAlreadyExists
    }
    
    // 3. å‰µå»ºè³‡æº
    resource := &Resource{
        Name:      req.Name,
        Type:      req.Type,
        IPAddress: req.IPAddress,
        TeamID:    req.TeamID,
        Status:    "active",
        Metadata:  req.Metadata,
        CreatedAt: time.Now(),
        UpdatedAt: time.Now(),
    }
    
    if err := s.repo.Create(ctx, resource); err != nil {
        return nil, fmt.Errorf("failed to create resource: %w", err)
    }
    
    // 4. è¨˜éŒ„å¯©è¨ˆæ—¥èªŒ
    go func() {
        s.auditService.LogEvent(context.Background(), AuditEvent{
            Type:      "RESOURCE_CREATED",
            Author:    GetUserFromContext(ctx),
            Summary:   fmt.Sprintf("Created resource %s", resource.Name),
            Details:   resource,
            Timestamp: time.Now(),
        })
    }()
    
    // 5. æ›´æ–°æŒ‡æ¨™
    s.metricsCollector.IncrementCounter("resources_created_total", 
        map[string]string{"type": resource.Type})
    
    return resource, nil
}
```

**3. Middleware Chain Patternï¼ˆä¸­é–“ä»¶éˆæ¨¡å¼ï¼‰**
```go
// internal/middleware/chain.go
func BuildMiddlewareChain() []gin.HandlerFunc {
    return []gin.HandlerFunc{
        // åŸºç¤ä¸­é–“ä»¶
        gin.Recovery(),
        gin.Logger(),
        
        // å®‰å…¨ä¸­é–“ä»¶
        CORSMiddleware(),
        SecurityHeadersMiddleware(),
        
        // æ¥­å‹™ä¸­é–“ä»¶
        RequestIDMiddleware(),
        AuthenticationMiddleware(),
        AuthorizationMiddleware(),
        
        // ç›£æ§ä¸­é–“ä»¶
        MetricsMiddleware(),
        TracingMiddleware(),
    }
}

// internal/middleware/auth.go
func AuthenticationMiddleware() gin.HandlerFunc {
    return func(c *gin.Context) {
        // 1. æª¢æŸ¥ Session Cookie
        if sessionToken := c.GetHeader("Session-Token"); sessionToken != "" {
            if user, err := ValidateSessionToken(sessionToken); err == nil {
                c.Set("user", user)
                c.Next()
                return
            }
        }
        
        // 2. æª¢æŸ¥ Bearer Token
        if authHeader := c.GetHeader("Authorization"); authHeader != "" {
            if token := strings.TrimPrefix(authHeader, "Bearer "); token != "" {
                if claims, err := ValidateJWTToken(token); err == nil {
                    c.Set("user", claims)
                    c.Next()
                    return
                }
            }
        }
        
        // 3. æœªèªè­‰
        c.JSON(401, gin.H{
            "error": gin.H{
                "code":    "AUTHENTICATION_REQUIRED",
                "message": "Valid authentication token required",
            },
        })
        c.Abort()
    }
}
```

### ğŸ¤– SRE Assistant æ¶æ§‹æ·±åº¦åˆ†æ

#### Agent-Based æ¶æ§‹

```mermaid
graph TB
    subgraph "ğŸŒ API Gateway"
        A[FastAPI Router] --> B[Request Validation]
        B --> C[Authentication]
        C --> D[Rate Limiting]
    end
    
    subgraph "ğŸ§  Agent Orchestration"
        E[Master Orchestrator] --> F[Task Queue]
        F --> G[Agent Pool]
        G --> H[Result Aggregator]
    end
    
    subgraph "ğŸ› ï¸ Tool Ecosystem"
        I[PrometheusQueryTool] --> J[LokiLogQueryTool]
        J --> K[ControlPlaneTool]
        K --> L[KubernetesAPITool]
        L --> M[GrafanaAPITool]
    end
    
    subgraph "ğŸ”® AI Processing"
        N[Prompt Engineering] --> O[Gemini API Client]
        O --> P[Response Processing]
        P --> Q[Context Management]
    end
    
    subgraph "ğŸ’¾ Data Management"
        R[(PostgreSQL Sessions)] --> S[(ChromaDB Vectors)]
        S --> T[Memory Cache]
        T --> U[Result Storage]
    end
    
    A --> E
    E --> I
    I --> N
    N --> R
```

#### å·¥å…·ç³»çµ±è¨­è¨ˆ

**1. åŸºç¤å·¥å…·æŠ½è±¡**
```python
# src/sre_assistant/tools/base.py
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional
from ..contracts import ToolResult, ToolError

class BaseTool(ABC):
    """æ‰€æœ‰è¨ºæ–·å·¥å…·çš„åŸºç¤é¡åˆ¥"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.timeout = config.get('timeout_seconds', 30)
        self.retry_count = config.get('retry_count', 3)
        
    @abstractmethod
    async def execute(self, context: Dict[str, Any]) -> ToolResult:
        """åŸ·è¡Œå·¥å…·çš„ä¸»è¦é‚è¼¯"""
        pass
    
    @abstractmethod
    def validate_context(self, context: Dict[str, Any]) -> bool:
        """é©—è­‰è¼¸å…¥ä¸Šä¸‹æ–‡æ˜¯å¦æœ‰æ•ˆ"""
        pass
    
    async def execute_with_retry(self, context: Dict[str, Any]) -> ToolResult:
        """å¸¶é‡è©¦æ©Ÿåˆ¶çš„åŸ·è¡ŒåŒ…è£"""
        last_error = None
        
        for attempt in range(self.retry_count):
            try:
                return await self.execute(context)
            except Exception as e:
                last_error = e
                if attempt < self.retry_count - 1:
                    await asyncio.sleep(2 ** attempt)  # æŒ‡æ•¸é€€é¿
                    
        return ToolResult(
            success=False,
            error=ToolError(
                code="EXECUTION_FAILED",
                message=f"Tool execution failed after {self.retry_count} attempts: {str(last_error)}"
            )
        )
```

**2. Prometheus æŸ¥è©¢å·¥å…·å¯¦ç¾ (åæ˜ ç•¶å‰ç¨‹å¼ç¢¼)**
```python
# src/sre_assistant/tools/prometheus_tool.py
import logging
import httpx
from typing import Dict, Any, Optional

# æ³¨æ„: æ­¤ç‚ºç°¡åŒ–ç‰ˆæœ¬ï¼Œåæ˜ ç•¶å‰ç¨‹å¼ç¢¼çš„çœŸå¯¦ç‹€æ³ã€‚
# ç¼ºå°‘è¶¨å‹¢åˆ†æã€å¥åº·è©•ä¼°ç­‰é€²éšåŠŸèƒ½ã€‚

class PrometheusQueryTool:
    """Prometheus æŸ¥è©¢å·¥å…· (åŸºç¤å¯¦ç¾)"""
    
    def __init__(self, config):
        self.base_url = config.prometheus.get("base_url", "http://prometheus:9090")
        self.timeout = config.prometheus.get("timeout_seconds", 15)
        
    async def execute(self, params: Dict[str, Any]) -> ToolResult:
        """åŸ·è¡Œ Prometheus æŸ¥è©¢"""
        # TODO: æ“´å……ä»¥æ”¯æ´æ›´è¤‡é›œçš„æŸ¥è©¢
        service = params.get("service", "")
        # ... å…¶ä»–åƒæ•¸æœªä½¿ç”¨ ...

        # å¯¦éš›ç¨‹å¼ç¢¼ä¸­ï¼Œæ­¤è™•é‚è¼¯åœ¨ workflow.py ä¸­ç‚ºæ¨¡æ“¬è³‡æ–™
        # æ­¤è™•å±•ç¤ºä¸€å€‹çœŸå¯¦çš„æŸ¥è©¢ç¯„ä¾‹
        return await self.query_golden_signals(service, "default", 30)

    async def query_golden_signals(self, service_name: str, namespace: str, duration: int) -> ToolResult:
        """æŸ¥è©¢å››å¤§é»ƒé‡‘è¨Šè™Ÿ"""
        # TODO: å¯¦ç¾çœŸæ­£çš„ä¸¦è¡ŒæŸ¥è©¢
        latency = await self._query_latency(service_name, namespace, duration)
        errors = await self._query_errors(service_name, namespace, duration)

        return ToolResult(
            success=True,
            data={**latency, **errors}
        )

    async def _query_latency(self, service: str, namespace: str, time_range: int) -> Dict[str, Any]:
        """æŸ¥è©¢å»¶é²æŒ‡æ¨™ (P99)"""
        query = f'histogram_quantile(0.99, rate(http_request_duration_seconds_bucket{{service="{service}"}}[5m]))'
        value = await self._execute_instant_query(query)
        return {"latency_p99": f"{value*1000:.2f}ms" if value is not None else "N/A"}

    async def _query_errors(self, service: str, namespace: str, time_range: int) -> Dict[str, Any]:
        """æŸ¥è©¢éŒ¯èª¤æŒ‡æ¨™"""
        error_query = f'sum(rate(http_requests_total{{service="{service}", status=~"5.."}}[5m]))'
        total_query = f'sum(rate(http_requests_total{{service="{service}"}}[5m]))'
        
        errors = await self._execute_instant_query(error_query)
        total = await self._execute_instant_query(total_query)
        
        error_rate = 0
        if total and total > 0:
            error_rate = (errors / total) * 100
        
        return {"error_rate": f"{error_rate:.2f}%"}

    async def _execute_instant_query(self, query: str) -> Optional[float]:
        """åŸ·è¡Œå³æ™‚æŸ¥è©¢"""
        try:
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                # ... å¯¦éš›çš„ httpx å‘¼å«é‚è¼¯ ...
                # ç‚ºç°¡åŒ–ï¼Œè¿”å›ä¸€å€‹æ¨¡æ“¬å€¼
                return 0.85 # æ¨¡æ“¬ CPU ä½¿ç”¨ç‡
        except Exception:
            return None
```

**3. å·¥ä½œæµç¨‹å”èª¿å™¨ (åæ˜ ç•¶å‰ç¨‹å¼ç¢¼)**
```python
# src/sre_assistant/workflow.py
import asyncio
from typing import Dict, Any
from .tools import PrometheusQueryTool, LokiLogQueryTool, ControlPlaneTool
from .contracts import SRERequest, ToolResult, Finding, SeverityLevel

class SREWorkflow:
    """è¨ºæ–·å·¥ä½œæµç¨‹å”èª¿å™¨ (éª¨æ¶å¯¦ç¾)"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.prometheus_tool = PrometheusQueryTool(config)
        # ... å…¶ä»–å·¥å…·åˆå§‹åŒ– ...
        
    async def execute(self, request: SRERequest) -> Dict[str, Any]:
        """åŸ·è¡Œä¸»è¦å·¥ä½œæµç¨‹"""
        # æ ¹æ“šè«‹æ±‚é¡å‹æ±ºå®šåŸ·è¡Œç­–ç•¥
        # TODO: å¢åŠ å° alert_diagnosis å’Œ ad_hoc_query çš„è™•ç†
        return await self._diagnose_deployment(request)
    
    async def _diagnose_deployment(self, request: SRERequest) -> Dict[str, Any]:
        """
        è¨ºæ–·éƒ¨ç½²å•é¡Œ (æ¨¡æ“¬å¯¦ç¾)
        
        æ³¨æ„: ç›®å‰å¤§éƒ¨åˆ†å·¥å…·å‘¼å«è¿”å›çš„æ˜¯æ¨¡æ“¬è³‡æ–™.
        """
        # TODO: å¯¦ç¾çœŸæ­£çš„ä¸¦è¡Œè¨ºæ–·
        # æ¨¡æ“¬å‘¼å«å·¥å…·
        metrics_result = await self._query_metrics(request.context)
        audit_result = await self._query_audit_logs(request.context)

        # TODO: å¯¦ç¾çœŸæ­£çš„çµæœåˆ†æèˆ‡ AI æ•´åˆ
        # åŸºæ–¼æ¨¡æ“¬è³‡æ–™çš„ç°¡å–®åˆ†æ
        findings = []
        issues = []

        if metrics_result.success and float(metrics_result.data.get("cpu_usage", "0%").replace("%", "")) > 80:
            findings.append(Finding(source="Prometheus", severity=SeverityLevel.P1, data=metrics_result.data))
            issues.append("CPU ä½¿ç”¨ç‡éé«˜")

        if audit_result.success and audit_result.data.get("recent_changes"):
            findings.append(Finding(source="Control-Plane", severity=SeverityLevel.P2, data=audit_result.data))
            issues.append("æœ€è¿‘æœ‰é…ç½®è®Šæ›´")

        # ç”Ÿæˆæ‘˜è¦å’Œå»ºè­°
        if issues:
            summary = f"ç™¼ç¾ {len(issues)} å€‹å•é¡Œ: {', '.join(issues)}"
            recommended_action = "å¯©æŸ¥ CPU ä½¿ç”¨ç‡ä¸¦æª¢æŸ¥æœ€è¿‘çš„é…ç½®è®Šæ›´"
        else:
            summary = "æœªç™¼ç¾æ˜é¡¯å•é¡Œ"
            recommended_action = "è«‹æ‰‹å‹•æª¢æŸ¥æ—¥èªŒ"

        return {
            "status": "COMPLETED",
            "summary": summary,
            "findings": [f.dict() for f in findings],
            "recommended_action": recommended_action,
            "confidence_score": 0.8 if issues else 0.5
        }
    
    async def _query_metrics(self, context: Dict[str, Any]) -> ToolResult:
        """æŸ¥è©¢ç›£æ§æŒ‡æ¨™ (æ¨¡æ“¬)"""
        await asyncio.sleep(0.5)
        return ToolResult(success=True, data={"cpu_usage": "85%"})

    async def _query_audit_logs(self, context: Dict[str, Any]) -> ToolResult:
        """æŸ¥è©¢å¯©è¨ˆæ—¥èªŒ (æ¨¡æ“¬)"""
        await asyncio.sleep(0.2)
        return ToolResult(success=True, data={"recent_changes": [{"user": "admin", "action": "UPDATE_CONFIG"}]})
```

---

## é–‹ç™¼å·¥ä½œæµç¨‹

### ğŸ”„ Git å·¥ä½œæµç¨‹

æˆ‘å€‘æ¡ç”¨ **GitFlow** çš„ç°¡åŒ–ç‰ˆæœ¬ï¼Œçµåˆ **Feature Branch** ç­–ç•¥ï¼š

```mermaid
gitgraph
    commit id: "Initial commit"
    
    branch develop
    checkout develop
    commit id: "Setup base architecture"
    
    branch feature/control-plane-api
    checkout feature/control-plane-api
    commit id: "Add resource management API"
    commit id: "Add authentication middleware"
    commit id: "Add tests"
    
    checkout develop
    merge feature/control-plane-api
    commit id: "Merge: Control Plane API"
    
    branch feature/sre-assistant-tools
    checkout feature/sre-assistant-tools
    commit id: "Add Prometheus tool"
    commit id: "Add Loki tool"
    commit id: "Add workflow engine"
    
    checkout develop
    merge feature/sre-assistant-tools
    commit id: "Merge: SRE Assistant tools"
    
    checkout main
    merge develop
    commit id: "Release v1.0.0"
    tag: "v1.0.0"
```

### ğŸ“ é–‹ç™¼æµç¨‹è©³è§£

#### 1. åŠŸèƒ½é–‹ç™¼æµç¨‹

```bash
# ğŸŒ¿ å‰µå»ºåŠŸèƒ½åˆ†æ”¯
git checkout develop
git pull origin develop
git checkout -b feature/new-diagnostic-tool

# ğŸ’» é–‹ç™¼åŠŸèƒ½
# ... é€²è¡Œä»£ç¢¼ç·¨å¯« ...

# ğŸ§ª é‹è¡Œæ¸¬è©¦
make test

# ğŸ“ æäº¤ä»£ç¢¼ï¼ˆéµå¾ª Conventional Commitsï¼‰
git add .
git commit -m "feat: æ–°å¢å®¹é‡åˆ†æè¨ºæ–·å·¥å…·

- å¯¦ç¾ CapacityAnalysisTool é¡åˆ¥
- æ–°å¢è¶¨å‹¢é æ¸¬ç®—æ³•
- æ·»åŠ ç›¸é—œå–®å…ƒæ¸¬è©¦
- æ›´æ–° API æ–‡æª”

Closes #123"

# ğŸš€ æ¨é€åˆ†æ”¯
git push origin feature/new-diagnostic-tool

# ğŸ“¤ å‰µå»º Pull Request
# é€é GitHub/GitLab UI å‰µå»º PR
```

#### 2. Commit è¨Šæ¯è¦ç¯„

æˆ‘å€‘ä½¿ç”¨ [Conventional Commits](https://www.conventionalcommits.org/zh-hant/) è¦ç¯„ï¼š

```
<é¡å‹>[å¯é¸çš„ä½œç”¨åŸŸ]: <æè¿°>

[å¯é¸çš„æ­£æ–‡]

[å¯é¸çš„è…³è¨»]
```

**é¡å‹æ¸…å–®**ï¼š
- `feat`: æ–°åŠŸèƒ½
- `fix`: éŒ¯èª¤ä¿®å¾©
- `docs`: æ–‡æª”è®Šæ›´
- `style`: ä»£ç¢¼æ ¼å¼èª¿æ•´ï¼ˆä¸å½±éŸ¿åŠŸèƒ½ï¼‰
- `refactor`: é‡æ§‹ä»£ç¢¼
- `test`: æ–°å¢æˆ–ä¿®æ”¹æ¸¬è©¦
- `chore`: ç¶­è­·æ€§å·¥ä½œ
- `perf`: æ€§èƒ½å„ªåŒ–
- `ci`: CI/CD ç›¸é—œè®Šæ›´

**ç¯„ä¾‹**ï¼š
```bash
# æ–°åŠŸèƒ½
git commit -m "feat(sre-assistant): æ–°å¢éƒ¨ç½²å¤±æ•—è‡ªå‹•å›æ»¾åŠŸèƒ½"

# éŒ¯èª¤ä¿®å¾©
git commit -m "fix(control-plane): ä¿®å¾©è³‡æºç¯©é¸ SQL æ³¨å…¥é¢¨éšª"

# æ–‡æª”æ›´æ–°
git commit -m "docs: æ›´æ–° API æ–‡æª”ä¸­çš„èªè­‰ç¯„ä¾‹"

# æ¸¬è©¦æ–°å¢
git commit -m "test(prometheus-tool): æ–°å¢æŒ‡æ¨™æŸ¥è©¢å·¥å…·çš„æ•´åˆæ¸¬è©¦"
```

#### 3. Code Review æª¢æŸ¥æ¸…å–®

**ğŸ” å¯©æŸ¥é‡é»**ï¼š

<details>
<summary>ğŸ“‹ åŠŸèƒ½æ­£ç¢ºæ€§</summary>

- [ ] åŠŸèƒ½å¯¦ç¾ç¬¦åˆéœ€æ±‚è¦æ ¼
- [ ] é‚Šç•Œæ¢ä»¶è™•ç†å®Œå–„
- [ ] éŒ¯èª¤è™•ç†æ©Ÿåˆ¶å¥å…¨
- [ ] å›æ­¸æ¸¬è©¦é€šé
</details>

<details>
<summary>ğŸ—ï¸ ä»£ç¢¼å“è³ª</summary>

- [ ] ä»£ç¢¼çµæ§‹æ¸…æ™°ï¼Œè·è²¬å–®ä¸€
- [ ] å‘½åè¦ç¯„ï¼Œèªç¾©æ˜ç¢º
- [ ] æ²’æœ‰é‡è¤‡ä»£ç¢¼
- [ ] è¤‡é›œé‚è¼¯æœ‰é©ç•¶è¨»é‡‹
</details>

<details>
<summary>ğŸ›¡ï¸ å®‰å…¨æ€§</summary>

- [ ] æ²’æœ‰ç¡¬ç·¨ç¢¼æ•æ„Ÿè³‡è¨Š
- [ ] è¼¸å…¥é©—è­‰å®Œæ•´
- [ ] SQL æ³¨å…¥é˜²è­·
- [ ] XSS é˜²è­·æªæ–½
</details>

<details>
<summary>âš¡ æ€§èƒ½è€ƒé‡</summary>

- [ ] æ²’æœ‰æ˜é¡¯çš„æ€§èƒ½ç“¶é ¸
- [ ] æ•¸æ“šåº«æŸ¥è©¢å„ªåŒ–
- [ ] è¨˜æ†¶é«”ä½¿ç”¨åˆç†
- [ ] ä¸¦ç™¼å®‰å…¨æ€§
</details>

### ğŸ§ª è‡ªå‹•åŒ– CI/CD

#### GitHub Actions å·¥ä½œæµç¨‹

```yaml
# .github/workflows/ci.yml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  test-control-plane:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: sre_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Go
      uses: actions/setup-go@v4
      with:
        go-version: '1.22'
        
    - name: Cache Go modules
      uses: actions/cache@v3
      with:
        path: |
          ~/.cache/go-build
          ~/go/pkg/mod
        key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
        
    - name: Install dependencies
      run: |
        cd services/control-plane
        go mod download
        
    - name: Run tests
      run: |
        cd services/control-plane
        go test -v -race -coverprofile=coverage.out ./...
        
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./services/control-plane/coverage.out
        flags: control-plane

  test-sre-assistant:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: sre_test
      
      chromadb:
        image: chromadb/chroma:latest
        ports:
          - 8001:8000

    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'
        
    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: latest
        virtualenvs-create: true
        virtualenvs-in-project: true
        
    - name: Cache Poetry dependencies
      uses: actions/cache@v3
      with:
        path: services/sre-assistant/.venv
        key: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }}
        
    - name: Install dependencies
      run: |
        cd services/sre-assistant
        poetry install --no-interaction --no-ansi
        
    - name: Run tests
      run: |
        cd services/sre-assistant
        poetry run pytest -v --cov=src --cov-report=xml
        
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./services/sre-assistant/coverage.xml
        flags: sre-assistant

  lint-and-format:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Go
      uses: actions/setup-go@v4
      with:
        go-version: '1.22'
        
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'
        
    - name: Install tools
      run: |
        # Go tools
        go install golang.org/x/tools/cmd/goimports@latest
        go install github.com/golangci/golangci-lint/cmd/golangci-lint@latest
        
        # Python tools
        pip install black isort flake8 mypy
        
    - name: Lint Go code
      run: |
        cd services/control-plane
        gofmt -s -w .
        goimports -w .
        golangci-lint run
        
    - name: Lint Python code
      run: |
        cd services/sre-assistant
        black --check .
        isort --check-only .
        flake8 .
        mypy src/

  security-scan:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'
        
    - name: Upload Trivy scan results
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: 'trivy-results.sarif'

  build-and-deploy:
    if: github.ref == 'refs/heads/main'
    needs: [test-control-plane, test-sre-assistant, lint-and-format, security-scan]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2
    
    - name: Login to Container Registry
      uses: docker/login-action@v2
      with:
        registry: ghcr.io
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Build and push Control Plane
      uses: docker/build-push-action@v4
      with:
        context: ./services/control-plane
        push: true
        tags: |
          ghcr.io/${{ github.repository }}/control-plane:latest
          ghcr.io/${{ github.repository }}/control-plane:${{ github.sha }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
    
    - name: Build and push SRE Assistant
      uses: docker/build-push-action@v4
      with:
        context: ./services/sre-assistant
        push: true
        tags: |
          ghcr.io/${{ github.repository }}/sre-assistant:latest
          ghcr.io/${{ github.repository }}/sre-assistant:${{ github.sha }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
    
    - name: Deploy to staging
      run: |
        # é€™è£¡æœƒè§¸ç™¼éƒ¨ç½²åˆ° staging ç’°å¢ƒ
        echo "Deploying to staging environment..."
        # kubectl apply -f k8s/staging/ ç­‰éƒ¨ç½²æŒ‡ä»¤
```

---

## ä»£ç¢¼è¦ç¯„èˆ‡æœ€ä½³å¯¦è¸

### ğŸ¯ Go ä»£ç¢¼è¦ç¯„

#### éåŒæ­¥ API å®¢æˆ¶ç«¯ (`sre_assistant_client.go`)

```go
// services/control-plane/internal/services/sre_assistant_client.go
package services

// ... (è³‡æ–™çµæ§‹å®šç¾©) ...

// DiagnoseDeployment å‘¼å« SRE Assistant çš„éåŒæ­¥ç«¯é»
func (c *SreAssistantClientImpl) DiagnoseDeployment(ctx context.Context, req *DiagnosticRequest) (*DiagnosticResponse, error) {
    // ... (å»ºç«‹è«‹æ±‚å’Œè¨­å®šæ¨™é ­) ...
    
    resp, err := c.httpClient.Do(httpReq)
    // ... (éŒ¯èª¤è™•ç†) ...

    // é©—è­‰ç‹€æ…‹ç¢¼æ˜¯å¦ç‚º 202 Accepted
    if resp.StatusCode != http.StatusAccepted {
        return nil, fmt.Errorf("éé æœŸçš„ç‹€æ…‹ç¢¼: %d", resp.StatusCode)
    }

    var respBody DiagnosticResponse
    // ... (è§£ç¢¼å›æ‡‰) ...
    return &respBody, nil
}

// PollDiagnosticStatus è¼ªè©¢è¨ºæ–·ç‹€æ…‹ç›´åˆ°å®Œæˆ
func (c *SreAssistantClientImpl) PollDiagnosticStatus(ctx context.Context, sessionID string) (*DiagnosticResult, error) {
    ticker := time.NewTicker(5 * time.Second) // æ¯ 5 ç§’è¼ªè©¢ä¸€æ¬¡
    defer ticker.Stop()
    
    timeoutCtx, cancel := context.WithTimeout(ctx, 5*time.Minute) // 5 åˆ†é˜è¶…æ™‚
    defer cancel()

    for {
        select {
        case <-timeoutCtx.Done():
            return nil, fmt.Errorf("è¼ªè©¢è¨ºæ–·çµæœè¶…æ™‚")
        case <-ticker.C:
            status, err := c.GetDiagnosticStatus(timeoutCtx, sessionID)
            if err != nil {
                // ... (è™•ç†æŸ¥è©¢éŒ¯èª¤) ...
                continue
            }
            
            if status.Status == "completed" {
                return status.Result, nil
            }
            if status.Status == "failed" {
                return nil, fmt.Errorf("è¨ºæ–·å¤±æ•—: %s", status.Error)
            }
            // "processing" ç‹€æ…‹å‰‡ç¹¼çºŒè¼ªè©¢
        }
    }
}
```

#### é …ç›®çµæ§‹è¦ç¯„

```go
// ğŸ“ internal/models/resource.go - è³‡æ–™æ¨¡å‹
package models

import (
    "time"
    "encoding/json"
)

// Resource è¡¨ç¤ºç³»çµ±ä¸­çš„è³‡æºå¯¦é«”
// éµå¾ª RESTful è¨­è¨ˆåŸå‰‡ï¼Œæ¯å€‹è³‡æºéƒ½æœ‰å”¯ä¸€è­˜åˆ¥ç¬¦
type Resource struct {
    ID        int             `json:"id" db:"id"`
    Name      string          `json:"name" db:"name" validate:"required,min=1,max=100"`
    Type      ResourceType    `json:"type" db:"type" validate:"required"`
    IPAddress string          `json:"ip_address" db:"ip_address" validate:"required,ip"`
    Status    ResourceStatus  `json:"status" db:"status"`
    TeamID    int             `json:"team_id" db:"team_id" validate:"required"`
    Metadata  json.RawMessage `json:"metadata" db:"metadata"`
    CreatedAt time.Time       `json:"created_at" db:"created_at"`
    UpdatedAt time.Time       `json:"updated_at" db:"updated_at"`
}

// ResourceType å®šç¾©è³‡æºé¡å‹çš„æšèˆ‰
type ResourceType string

const (
    ResourceTypeServer  ResourceType = "server"
    ResourceTypeNetwork ResourceType = "network"
    ResourceTypeApp     ResourceType = "app"
)

// IsValid æª¢æŸ¥è³‡æºé¡å‹æ˜¯å¦æœ‰æ•ˆ
func (rt ResourceType) IsValid() bool {
    switch rt {
    case ResourceTypeServer, ResourceTypeNetwork, ResourceTypeApp:
        return true
    }
    return false
}

// ResourceStatus å®šç¾©è³‡æºç‹€æ…‹çš„æšèˆ‰
type ResourceStatus string

const (
    ResourceStatusActive   ResourceStatus = "active"
    ResourceStatusInactive ResourceStatus = "inactive"
    ResourceStatusMaintenance ResourceStatus = "maintenance"
)
```

#### éŒ¯èª¤è™•ç†æœ€ä½³å¯¦è¸

```go
// ğŸ“ internal/errors/errors.go - çµ±ä¸€éŒ¯èª¤è™•ç†
package errors

import (
    "fmt"
    "net/http"
)

// AppError ä»£è¡¨æ‡‰ç”¨ç¨‹å¼ä¸­çš„æ¥­å‹™éŒ¯èª¤
type AppError struct {
    Code       string                 `json:"code"`
    Message    string                 `json:"message"`
    Details    map[string]interface{} `json:"details,omitempty"`
    HTTPStatus int                    `json:"-"`
    Cause      error                  `json:"-"`
}

func (e *AppError) Error() string {
    if e.Cause != nil {
        return fmt.Sprintf("%s: %v", e.Message, e.Cause)
    }
    return e.Message
}

// é å®šç¾©çš„æ¥­å‹™éŒ¯èª¤
var (
    ErrResourceNotFound = &AppError{
        Code:       "RESOURCE_NOT_FOUND",
        Message:    "Resource not found",
        HTTPStatus: http.StatusNotFound,
    }
    
    ErrResourceAlreadyExists = &AppError{
        Code:       "RESOURCE_ALREADY_EXISTS", 
        Message:    "Resource already exists",
        HTTPStatus: http.StatusConflict,
    }
    
    ErrInvalidInput = &AppError{
        Code:       "INVALID_INPUT",
        Message:    "Invalid input parameters",
        HTTPStatus: http.StatusBadRequest,
    }
)

// NewValidationError å‰µå»ºé©—è­‰éŒ¯èª¤
func NewValidationError(field string, reason string) *AppError {
    return &AppError{
        Code:       "VALIDATION_ERROR",
        Message:    "Input validation failed",
        HTTPStatus: http.StatusUnprocessableEntity,
        Details: map[string]interface{}{
            "field":  field,
            "reason": reason,
        },
    }
}

// WrapError åŒ…è£åº•å±¤éŒ¯èª¤
func WrapError(err error, appErr *AppError) *AppError {
    newErr := *appErr // è¤‡è£½
    newErr.Cause = err
    return &newErr
}
```

#### HTTP è™•ç†å™¨æ¨¡å¼

```go
// ğŸ“ internal/handlers/resource_handler.go - HTTP è™•ç†å™¨
package handlers

import (
    "net/http"
    "strconv"
    
    "github.com/gin-gonic/gin"
    "github.com/detectviz/sre-platform/internal/services"
    "github.com/detectviz/sre-platform/internal/errors"
)

type ResourceHandler struct {
    resourceService *services.ResourceService
}

func NewResourceHandler(resourceService *services.ResourceService) *ResourceHandler {
    return &ResourceHandler{
        resourceService: resourceService,
    }
}

// GetResources ç²å–è³‡æºåˆ—è¡¨
// @Summary ç²å–è³‡æºåˆ—è¡¨
// @Description æ ¹æ“šç¯©é¸æ¢ä»¶ç²å–è³‡æºåˆ—è¡¨ï¼Œæ”¯æ´åˆ†é 
// @Tags resources
// @Accept json
// @Produce json
// @Param page query int false "é ç¢¼" default(1)
// @Param limit query int false "æ¯é æ•¸é‡" default(20)
// @Param type query string false "è³‡æºé¡å‹" Enums(server,network,app)
// @Success 200 {object} ResourceListResponse
// @Failure 400 {object} ErrorResponse
// @Router /api/v1/resources [get]
func (h *ResourceHandler) GetResources(c *gin.Context) {
    // 1. è§£ææŸ¥è©¢åƒæ•¸
    filters, err := h.parseResourceFilters(c)
    if err != nil {
        h.handleError(c, err)
        return
    }
    
    // 2. èª¿ç”¨æœå‹™å±¤
    resources, total, err := h.resourceService.GetResources(c.Request.Context(), filters)
    if err != nil {
        h.handleError(c, err)
        return
    }
    
    // 3. æ§‹å»ºéŸ¿æ‡‰
    response := ResourceListResponse{
        Data: resources,
        Pagination: PaginationInfo{
            Page:       filters.Page,
            Limit:      filters.Limit,
            Total:      total,
            TotalPages: (total + filters.Limit - 1) / filters.Limit,
        },
    }
    
    c.JSON(http.StatusOK, response)
}

// CreateResource å‰µå»ºæ–°è³‡æº
func (h *ResourceHandler) CreateResource(c *gin.Context) {
    var req CreateResourceRequest
    
    // 1. ç¶å®šè«‹æ±‚é«”
    if err := c.ShouldBindJSON(&req); err != nil {
        h.handleError(c, errors.WrapError(err, errors.ErrInvalidInput))
        return
    }
    
    // 2. é©—è­‰è¼¸å…¥
    if err := h.validateCreateResourceRequest(&req); err != nil {
        h.handleError(c, err)
        return
    }
    
    // 3. ç²å–ç•¶å‰ä½¿ç”¨è€…
    user := GetUserFromContext(c)
    
    // 4. èª¿ç”¨æœå‹™å±¤
    resource, err := h.resourceService.CreateResource(c.Request.Context(), &req, user)
    if err != nil {
        h.handleError(c, err)
        return
    }
    
    c.JSON(http.StatusCreated, resource)
}

// parseResourceFilters è§£æè³‡æºç¯©é¸åƒæ•¸
func (h *ResourceHandler) parseResourceFilters(c *gin.Context) (*services.ResourceFilters, error) {
    filters := &services.ResourceFilters{
        Page:  1,
        Limit: 20,
    }
    
    // è§£æé ç¢¼
    if pageStr := c.Query("page"); pageStr != "" {
        if page, err := strconv.Atoi(pageStr); err == nil && page > 0 {
            filters.Page = page
        }
    }
    
    // è§£ææ¯é æ•¸é‡
    if limitStr := c.Query("limit"); limitStr != "" {
        if limit, err := strconv.Atoi(limitStr); err == nil && limit > 0 && limit <= 100 {
            filters.Limit = limit
        }
    }
    
    // è§£æè³‡æºé¡å‹
    if typeStr := c.Query("type"); typeStr != "" {
        resourceType := models.ResourceType(typeStr)
        if !resourceType.IsValid() {
            return nil, errors.NewValidationError("type", "invalid resource type")
        }
        filters.Type = &resourceType
    }
    
    // å…¶ä»–ç¯©é¸æ¢ä»¶...
    filters.Status = c.Query("status")
    filters.Search = c.Query("search")
    
    if teamIDStr := c.Query("team_id"); teamIDStr != "" {
        if teamID, err := strconv.Atoi(teamIDStr); err == nil {
            filters.TeamID = &teamID
        }
    }
    
    return filters, nil
}

// handleError çµ±ä¸€éŒ¯èª¤è™•ç†
func (h *ResourceHandler) handleError(c *gin.Context, err error) {
    if appErr, ok := err.(*errors.AppError); ok {
        c.JSON(appErr.HTTPStatus, ErrorResponse{
            Error: ErrorDetail{
                Code:    appErr.Code,
                Message: appErr.Message,
                Details: appErr.Details,
            },
        })
    } else {
        // æœªé æœŸçš„éŒ¯èª¤ï¼Œè¨˜éŒ„æ—¥èªŒä½†ä¸æš´éœ²è©³ç´°è³‡è¨Š
        logger.Error("Unexpected error", "error", err)
        c.JSON(http.StatusInternalServerError, ErrorResponse{
            Error: ErrorDetail{
                Code:    "INTERNAL_ERROR",
                Message: "An internal error occurred",
            },
        })
    }
}
```

### ğŸ Python ä»£ç¢¼è¦ç¯„

#### éåŒæ­¥ API å¯¦ç¾ (`main.py`)
```python
# services/sre-assistant/src/sre_assistant/main.py
from fastapi import FastAPI, BackgroundTasks, HTTPException
import uuid
from typing import Dict

# å‡è¨­ tasks æ˜¯ä¸€å€‹å…±äº«çš„ã€ç”¨æ–¼å„²å­˜ä»»å‹™ç‹€æ…‹çš„å­—å…¸
# åœ¨ç”Ÿç”¢ç’°å¢ƒä¸­ï¼Œæ‡‰ä½¿ç”¨ Redis æˆ–è³‡æ–™åº«
tasks: Dict[uuid.UUID, DiagnosticStatus] = {}

# èƒŒæ™¯ä»»å‹™åŸ·è¡Œå™¨
async def run_workflow_bg(session_id: uuid.UUID, request: DiagnosticRequest):
    tasks[session_id] = DiagnosticStatus(session_id=session_id, status="processing")
    # workflow.execute ç¾åœ¨æœƒæ›´æ–° tasks å­—å…¸è€Œä¸æ˜¯è¿”å›å€¼
    await workflow.execute(session_id, request, tasks)

# API ç«¯é»
@app.post("/api/v1/diagnostics/deployment", status_code=202)
async def diagnose_deployment(
    request: DiagnosticRequest,
    background_tasks: BackgroundTasks
) -> DiagnosticResponse:
    session_id = uuid.uuid4()
    background_tasks.add_task(run_workflow_bg, session_id, request)
    return DiagnosticResponse(session_id=session_id, status="accepted")

@app.get("/api/v1/diagnostics/{session_id}/status")
async def get_diagnostic_status(session_id: uuid.UUID) -> DiagnosticStatus:
    task = tasks.get(session_id)
    if not task:
        raise HTTPException(status_code=404, detail="æ‰¾ä¸åˆ°è¨ºæ–·ä»»å‹™")
    return task
```

#### å·¥ä½œæµç¨‹å¯¦ç¾ (`workflow.py`)

```python
# services/sre-assistant/src/sre_assistant/workflow.py
class SREWorkflow:
    # ... (åˆå§‹åŒ–ä¸è®Š) ...
    
    async def execute(self, session_id: uuid.UUID, request: DiagnosticRequest, tasks: Dict[uuid.UUID, DiagnosticStatus]):
        """
        åœ¨èƒŒæ™¯åŸ·è¡Œå·¥ä½œæµç¨‹ï¼Œä¸¦æ›´æ–°å…±äº«çš„ tasks å­—å…¸
        """
        try:
            # 1. æ›´æ–°åˆå§‹ç‹€æ…‹
            tasks[session_id].current_step = "é–‹å§‹è¨ºæ–·"
            tasks[session_id].progress = 10
            
            # 2. åŸ·è¡Œå·¥å…· (æ­¤è™•ç‚ºç°¡åŒ–ç¯„ä¾‹)
            results = await self._run_tools(request)
            tasks[session_id].progress = 80
            
            # 3. åˆ†æçµæœ
            final_result = self._analyze_results(results)
            
            # 4. æ›´æ–°æœ€çµ‚ç‹€æ…‹
            tasks[session_id].status = "completed"
            tasks[session_id].progress = 100
            tasks[session_id].result = final_result
            
        except Exception as e:
            # 5. æ›´æ–°å¤±æ•—ç‹€æ…‹
            tasks[session_id].status = "failed"
            tasks[session_id].error = str(e)
```


#### é¡å‹è¨»è§£èˆ‡æ–‡æª”å­—ç¬¦ä¸²

```python
# src/sre_assistant/contracts.py
from typing import Dict, List, Optional, Union, Literal
from pydantic import BaseModel, Field, validator
from datetime import datetime
from enum import Enum

class SeverityLevel(str, Enum):
    """äº‹ä»¶åš´é‡ç¨‹åº¦ç­‰ç´š
    
    å®šç¾©ç³»çµ±ä¸­äº‹ä»¶çš„åš´é‡ç¨‹åº¦åˆ†ç´šï¼Œç”¨æ–¼å„ªå…ˆç´šæ’åºå’Œè³‡æºåˆ†é…
    """
    P0 = "P0"  # é—œéµäº‹ä»¶ - ç³»çµ±å®Œå…¨ä¸å¯ç”¨
    P1 = "P1"  # é«˜å„ªå…ˆç´š - æ ¸å¿ƒåŠŸèƒ½å—å½±éŸ¿
    P2 = "P2"  # ä¸­å„ªå…ˆç´š - éƒ¨åˆ†åŠŸèƒ½å—å½±éŸ¿
    P3 = "P3"  # ä½å„ªå…ˆç´š - è¼•å¾®å½±éŸ¿æˆ–æ”¹é€²

class DiagnosticRequest(BaseModel):
    """è¨ºæ–·è«‹æ±‚çš„åŸºç¤æ¨¡å‹
    
    æ‰€æœ‰è¨ºæ–·è«‹æ±‚éƒ½æ‡‰è©²ç¹¼æ‰¿æ­¤åŸºç¤é¡åˆ¥ï¼Œæä¾›çµ±ä¸€çš„è«‹æ±‚æ ¼å¼å’Œé©—è­‰
    
    Attributes:
        request_id: è«‹æ±‚çš„å”¯ä¸€è­˜åˆ¥ç¬¦ï¼Œç”¨æ–¼è¿½è¹¤å’Œæ—¥èªŒè¨˜éŒ„
        service_name: ç›®æ¨™æœå‹™åç¨±
        severity: å•é¡Œåš´é‡ç¨‹åº¦
        context: è¨ºæ–·ä¸Šä¸‹æ–‡æ•¸æ“šï¼ŒåŒ…å«ç‰¹å®šè¨ºæ–·é¡å‹æ‰€éœ€çš„åƒæ•¸
        metadata: é¡å¤–çš„å…ƒæ•¸æ“šè³‡è¨Š
    """
    
    request_id: str = Field(
        ..., 
        description="è«‹æ±‚å”¯ä¸€è­˜åˆ¥ç¬¦",
        example="diag_20250905_143000_001"
    )
    
    service_name: str = Field(
        ..., 
        min_length=1, 
        max_length=100,
        description="ç›®æ¨™æœå‹™åç¨±",
        example="payment-service"
    )
    
    severity: SeverityLevel = Field(
        default=SeverityLevel.P2,
        description="å•é¡Œåš´é‡ç¨‹åº¦"
    )
    
    context: Dict[str, Union[str, int, float, bool, List, Dict]] = Field(
        default_factory=dict,
        description="è¨ºæ–·ä¸Šä¸‹æ–‡æ•¸æ“š"
    )
    
    metadata: Optional[Dict[str, Union[str, int, float, bool]]] = Field(
        default=None,
        description="é¡å¤–å…ƒæ•¸æ“š"
    )
    
    requested_at: datetime = Field(
        default_factory=datetime.utcnow,
        description="è«‹æ±‚æ™‚é–“æˆ³"
    )
    
    @validator('service_name')
    def validate_service_name(cls, v: str) -> str:
        """é©—è­‰æœå‹™åç¨±æ ¼å¼
        
        Args:
            v: æœå‹™åç¨±å­—ç¬¦ä¸²
            
        Returns:
            str: é©—è­‰å¾Œçš„æœå‹™åç¨±
            
        Raises:
            ValueError: ç•¶æœå‹™åç¨±æ ¼å¼ä¸æ­£ç¢ºæ™‚
        """
        if not v.replace('-', '').replace('_', '').isalnum():
            raise ValueError('æœå‹™åç¨±åªèƒ½åŒ…å«å­—æ¯ã€æ•¸å­—ã€é€£å­—ç¬¦å’Œä¸‹åŠƒç·š')
        return v.lower()
    
    @validator('context')
    def validate_context(cls, v: Dict) -> Dict:
        """é©—è­‰ä¸Šä¸‹æ–‡æ•¸æ“š
        
        ç¢ºä¿ä¸Šä¸‹æ–‡æ•¸æ“šä¸­ä¸åŒ…å«æ•æ„Ÿè³‡è¨Šï¼Œä¸¦ä¸”æ•¸æ“šçµæ§‹åˆç†
        
        Args:
            v: ä¸Šä¸‹æ–‡å­—å…¸
            
        Returns:
            Dict: é©—è­‰å¾Œçš„ä¸Šä¸‹æ–‡æ•¸æ“š
        """
        # æª¢æŸ¥æ˜¯å¦åŒ…å«æ•æ„Ÿéµ
        sensitive_keys = {'password', 'token', 'secret', 'key', 'credential'}
        for key in v.keys():
            if any(sensitive in key.lower() for sensitive in sensitive_keys):
                raise ValueError(f'ä¸Šä¸‹æ–‡ä¸­ä¸æ‡‰åŒ…å«æ•æ„Ÿè³‡è¨Š: {key}')
        
        return v

class DiagnosticResult(BaseModel):
    """è¨ºæ–·çµæœçš„çµ±ä¸€æ ¼å¼
    
    æ‰€æœ‰è¨ºæ–·å·¥å…·å’Œå·¥ä½œæµç¨‹éƒ½æ‡‰è©²è¿”å›æ­¤æ ¼å¼çš„çµæœ
    """
    
    request_id: str = Field(..., description="å°æ‡‰çš„è«‹æ±‚ ID")
    
    status: Literal["PROCESSING", "COMPLETED", "FAILED"] = Field(
        ..., 
        description="è¨ºæ–·ç‹€æ…‹"
    )
    
    summary: str = Field(
        ..., 
        description="è¨ºæ–·çµæœæ‘˜è¦",
        max_length=500
    )
    
    findings: List[Dict[str, Union[str, float, int, List, Dict]]] = Field(
        default_factory=list,
        description="è©³ç´°ç™¼ç¾æ¸…å–®"
    )
    
    recommendations: List[Dict[str, Union[str, int, List]]] = Field(
        default_factory=list,
        description="å»ºè­°è¡Œå‹•æ¸…å–®"
    )
    
    confidence_score: float = Field(
        default=0.0,
        ge=0.0,
        le=1.0,
        description="çµæœä¿¡å¿ƒåˆ†æ•¸ (0-1)"
    )
    
    execution_time_ms: int = Field(
        default=0,
        ge=0,
        description="åŸ·è¡Œæ™‚é–“ï¼ˆæ¯«ç§’ï¼‰"
    )
    
    metadata: Dict[str, Union[str, int, float, bool, List]] = Field(
        default_factory=dict,
        description="åŸ·è¡Œå…ƒæ•¸æ“š"
    )
    
    completed_at: datetime = Field(
        default_factory=datetime.utcnow,
        description="å®Œæˆæ™‚é–“æˆ³"
    )
    
    @validator('confidence_score')
    def validate_confidence_score(cls, v: float) -> float:
        """é©—è­‰ä¿¡å¿ƒåˆ†æ•¸çš„åˆç†æ€§"""
        if v < 0.0 or v > 1.0:
            raise ValueError('ä¿¡å¿ƒåˆ†æ•¸å¿…é ˆåœ¨ 0.0 åˆ° 1.0 ä¹‹é–“')
        return round(v, 3)  # ä¿ç•™ä¸‰ä½å°æ•¸
```    

#### å¸¸è¦‹å•é¡Œå¿«é€Ÿè§£æ±º

<details>
<summary>ğŸš¨ PostgreSQL é€£æ¥å¤±æ•—</summary>

```bash
# æª¢æŸ¥æœå‹™ç‹€æ…‹
sudo systemctl status postgresql

# é‡å•Ÿæœå‹™
sudo systemctl restart postgresql

# æª¢æŸ¥é€£æ¥
sudo -u postgres psql -c "SELECT version();"

# é‡ç½®è³‡æ–™åº«ï¼ˆè¬¹æ…ä½¿ç”¨ï¼‰
sudo -u postgres dropdb sre_dev || true
sudo -u postgres createdb sre_dev
```
</details>

<details>
<summary>ğŸš¨ Keycloak å•Ÿå‹•ç·©æ…¢</summary>

```bash
# æª¢æŸ¥å•Ÿå‹•æ—¥èªŒ
tail -f /tmp/keycloak.log

# å¢åŠ  JVM è¨˜æ†¶é«”ï¼ˆå¦‚æœè¨˜æ†¶é«”ä¸è¶³ï¼‰
export JAVA_OPTS="-Xms512m -Xmx2g"

# æ‰‹å‹•å•Ÿå‹•ï¼ˆåµéŒ¯æ¨¡å¼ï¼‰
/opt/keycloak/bin/kc.sh start-dev --log-level=DEBUG
```
</details>

<details>
<summary>ğŸš¨ Poetry ä¾è³´è¡çª</summary>

```bash
# æ¸…ç† Poetry å¿«å–
poetry cache clear pypi --all

# é‡æ–°å®‰è£ä¾è³´
cd services/sre-assistant
poetry install --sync

# æª¢æŸ¥ä¾è³´è¡çª
poetry check
```
</details>

---

## æ¸¬è©¦ç­–ç•¥èˆ‡å¯¦è¸

### ğŸ§ª æ¸¬è©¦é‡‘å­—å¡”

```mermaid
pyramid
    title æ¸¬è©¦é‡‘å­—å¡”
    
    section E2E Tests
        description: ç«¯åˆ°ç«¯æ¸¬è©¦
        value: 10%
    
    section Integration Tests  
        description: æ•´åˆæ¸¬è©¦
        value: 20%
    
    section Unit Tests
        description: å–®å…ƒæ¸¬è©¦  
        value: 70%
```

### ğŸ“Š æ¸¬è©¦è¦†è“‹ç‡ç›®æ¨™

| çµ„ä»¶ | å–®å…ƒæ¸¬è©¦ | æ•´åˆæ¸¬è©¦ | E2E æ¸¬è©¦ | ç¸½è¦†è“‹ç‡ç›®æ¨™ |
|------|----------|----------|----------|-------------|
| **Control Plane** | 80%+ | 70%+ | 60%+ | 85%+ |
| **SRE Assistant** | 85%+ | 75%+ | 50%+ | 80%+ |
| **å…±äº«çµ„ä»¶** | 90%+ | 80%+ | N/A | 90%+ |

---

## èª¿è©¦èˆ‡æ•…éšœæ’é™¤

### ğŸ” æ—¥èªŒç³»çµ±è¨­è¨ˆ

#### çµ±ä¸€æ—¥èªŒæ ¼å¼

```go
// Go æœå‹™çš„çµæ§‹åŒ–æ—¥èªŒ
logger.Info("Resource created successfully",
    "resource_id", resource.ID,
    "resource_name", resource.Name,
    "user_id", user.ID,
    "team_id", resource.TeamID,
    "duration_ms", time.Since(startTime).Milliseconds(),
)

logger.Error("Failed to connect to database",
    "error", err,
    "operation", "create_resource",
    "retry_count", retryCount,
    "database_host", config.DatabaseHost,
)
```

```python
# Python æœå‹™çš„çµæ§‹åŒ–æ—¥èªŒ
logger.info(
    "Diagnostic workflow completed",
    extra={
        "request_id": request.request_id,
        "service_name": request.service_name,
        "execution_time_ms": execution_time,
        "confidence_score": result.confidence_score,
        "tools_used": list(results.keys())
    }
)

logger.error(
    "Tool execution failed",
    extra={
        "tool_name": tool.__class__.__name__,
        "error_code": error.code,
        "error_message": error.message,
        "context": context,
        "attempt": attempt
    },
    exc_info=True
)
```

### ğŸ› èª¿è©¦æŠ€å·§

#### 1. åˆ†æ•£å¼è¿½è¹¤

```python
# src/sre_assistant/middleware/tracing.py
import opentelemetry.trace as trace
from opentelemetry.propagate import extract
from fastapi import Request

tracer = trace.get_tracer(__name__)

async def trace_request(request: Request, call_next):
    """ç‚ºè«‹æ±‚æ·»åŠ åˆ†æ•£å¼è¿½è¹¤"""
    # å¾è«‹æ±‚æ¨™é ­ä¸­æå–è¿½è¹¤ä¸Šä¸‹æ–‡
    context = extract(request.headers)
    
    with tracer.start_as_current_span(
        f"{request.method} {request.url.path}",
        context=context
    ) as span:
        # æ·»åŠ è«‹æ±‚å±¬æ€§
        span.set_attribute("http.method", request.method)
        span.set_attribute("http.url", str(request.url))
        span.set_attribute("user.id", request.state.user.id if hasattr(request.state, 'user') else "anonymous")
        
        try:
            response = await call_next(request)
            span.set_attribute("http.status_code", response.status_code)
            return response
        except Exception as e:
            span.record_exception(e)
            span.set_status(trace.Status(trace.StatusCode.ERROR, str(e)))
            raise
```

#### 2. æœ¬åœ°èª¿è©¦é…ç½®

```yaml
# docker-compose.debug.yml
version: '3.8'
services:
  control-plane:
    build:
      context: ./services/control-plane
      dockerfile: Dockerfile.debug
    ports:
      - "8081:8081"
      - "2345:2345"  # Delve debugger port
    environment:
      - GO_ENV=debug
      - LOG_LEVEL=debug
    volumes:
      - ./services/control-plane:/app
    command: |
      bash -c "
        go install github.com/go-delve/delve/cmd/dlv@latest &&
        dlv debug --headless --listen=:2345 --api-version=2 --accept-multiclient cmd/server/main.go
      "

  sre-assistant:
    build:
      context: ./services/sre-assistant
      dockerfile: Dockerfile.debug
    ports:
      - "8000:8000"
      - "5678:5678"  # debugpy port
    environment:
      - PYTHON_ENV=debug
      - LOG_LEVEL=debug
    volumes:
      - ./services/sre-assistant:/app
    command: |
      bash -c "
        poetry install &&
        poetry run python -m debugpy --listen 0.0.0.0:5678 --wait-for-client -m sre_assistant.main
      "
```

#### 3. æ€§èƒ½åˆ†æå·¥å…·

```go
// internal/middleware/profiling.go
package middleware

import (
    "net/http"
    _ "net/http/pprof"
    "github.com/gin-gonic/gin"
)

func ProfilingRoutes() gin.HandlerFunc {
    return gin.WrapH(http.DefaultServeMux)
}

// åœ¨é–‹ç™¼æ¨¡å¼ä¸‹å•Ÿç”¨æ€§èƒ½åˆ†æ
if os.Getenv("GO_ENV") == "development" {
    go func() {
        log.Println("Starting pprof server on :6060")
        log.Println(http.ListenAndServe("localhost:6060", nil))
    }()
}
```

```python
# src/sre_assistant/middleware/profiling.py
import cProfile
import pstats
from fastapi import Request, Response

async def profile_request(request: Request, call_next):
    """ç‚ºè«‹æ±‚æ·»åŠ æ€§èƒ½åˆ†æ"""
    if request.query_params.get("profile") == "true":
        profiler = cProfile.Profile()
        profiler.enable()
        
        try:
            response = await call_next(request)
            return response
        finally:
            profiler.disable()
            stats = pstats.Stats(profiler)
            stats.sort_stats('cumulative')
            
            # å°‡æ€§èƒ½åˆ†æçµæœæ·»åŠ åˆ°éŸ¿æ‡‰æ¨™é ­
            response.headers["X-Profile-Stats"] = stats.get_stats_profile()
    else:
        return await call_next(request)
```

---

**ğŸ“„ æ–‡ä»¶ç‹€æ…‹**: ğŸš§ æŒçºŒæ›´æ–°ä¸­  
**ğŸ”„ ä¸‹æ¬¡æ›´æ–°**: æ·»åŠ éƒ¨ç½²èˆ‡ç¶­è­·ç« ç¯€  
**ğŸ‘¥ ç¶­è­·è€…**: SRE Platform é–‹ç™¼åœ˜éšŠ  
**ğŸ“§ è¯ç¹«æ–¹å¼**: dev-team@detectviz.com 


---


