# services/sre-assistant/src/sre_assistant/tools/loki_tool.py
"""
Loki æ—¥èªŒæŸ¥è©¢å·¥å…·
ç”¨æ–¼æŸ¥è©¢å’Œåˆ†ææœå‹™æ—¥èªŒ
"""

import asyncio
import structlog
import httpx
import json
import re
from typing import Dict, Any, Optional, List
from datetime import datetime, timedelta, timezone

from ..contracts import ToolResult, ToolError

logger = structlog.get_logger(__name__)


class LokiLogQueryTool:
    """
    Loki æ—¥èªŒæŸ¥è©¢å·¥å…·
    """
    
    def __init__(self, config, http_client: httpx.AsyncClient):
        """åˆå§‹åŒ– Loki å·¥å…·"""
        self.base_url = config.loki.base_url
        self.timeout = config.loki.timeout_seconds
        self.default_limit = config.loki.default_limit
        self.max_time_range = config.loki.max_time_range
        self.http_client = http_client
        
        logger.info(f"âœ… Loki å·¥å…·åˆå§‹åŒ– (ä½¿ç”¨å…±äº« HTTP å®¢æˆ¶ç«¯): {self.base_url}")

    async def check_health(self) -> bool:
        """
        åŸ·è¡Œå° Loki çš„å¥åº·æª¢æŸ¥ã€‚
        """
        try:
            response = await self.http_client.get(f"{self.base_url}/ready", timeout=self.timeout)
            response.raise_for_status()
            if response.text.strip() == "ready":
                logger.debug(f"Loki health check successful: {response.status_code}")
                return True
            logger.warning(f"Loki health check response is not 'ready': {response.text}")
            return False
        except (httpx.HTTPStatusError, httpx.RequestError) as e:
            logger.warning(f"Loki health check failed: {e}")
            return False
    
    async def execute(self, params: Dict[str, Any]) -> ToolResult:
        """
        åŸ·è¡Œ Loki æ—¥èªŒæŸ¥è©¢
        """
        try:
            service = params.get("service", "")
            namespace = params.get("namespace", "default")
            log_level = params.get("log_level", "error")
            pattern = params.get("pattern", "")
            time_range = params.get("time_range", 30)
            limit = params.get("limit", self.default_limit)
            
            logger.info(f"ğŸ“ æŸ¥è©¢ Loki: service={service}, level={log_level}, pattern={pattern}")
            
            logs = await self._query_logs(service, namespace, log_level, pattern, time_range, limit)
            analysis = self._analyze_logs(logs)
            
            return ToolResult(
                success=True,
                data={"logs": logs, "analysis": analysis, "query_params": {"service": service, "namespace": namespace, "log_level": log_level, "time_range": f"{time_range}m"}},
                metadata={"source": "loki", "timestamp": datetime.now(timezone.utc).isoformat(), "total_logs": len(logs)}
            )
            
        except httpx.HTTPStatusError as e:
            return self._handle_error(e, params)
        except httpx.TimeoutException as e:
            return self._handle_error(e, params)
        except httpx.ConnectError as e:
            return self._handle_error(e, params)
        except Exception as e:
            return self._handle_error(e, params)
    
    def _handle_error(self, e: Exception, params: Optional[Dict]) -> ToolResult:
        if isinstance(e, httpx.HTTPStatusError):
            logger.error(f"âŒ Loki API æŸ¥è©¢å¤±æ•—: {e.response.status_code} - {e.response.text}", exc_info=True)
            return ToolResult(success=False, error=ToolError(code="HTTP_STATUS_ERROR", message=f"Loki API returned HTTP {e.response.status_code}", details={"status_code": e.response.status_code, "response_body": e.response.text[:500], "request_url": str(e.request.url), "params": params}))
        if isinstance(e, httpx.TimeoutException):
            logger.error(f"âŒ Loki API è«‹æ±‚è¶…æ™‚: {e}", exc_info=True)
            return ToolResult(success=False, error=ToolError(code="TIMEOUT_ERROR", message=f"Loki API request timed out", details={"timeout_seconds": self.timeout, "request_url": str(e.request.url), "params": params}))
        if isinstance(e, httpx.ConnectError):
            logger.error(f"âŒ Loki API é€£ç·šå¤±æ•—: {e}", exc_info=True)
            return ToolResult(success=False, error=ToolError(code="CONNECTION_ERROR", message="Failed to connect to Loki", details={"base_url": self.base_url, "params": params}))
        
        logger.error(f"âŒ Loki å·¥å…·åŸ·è¡Œæ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}", exc_info=True)
        return ToolResult(success=False, error=ToolError(code="UNEXPECTED_ERROR", message=str(e), details={"error_type": type(e).__name__, "params": params}))

    async def _query_logs(self, service: str, namespace: str, log_level: str, pattern: str, time_range: int, limit: int) -> List[Dict[str, Any]]:
        """
        æŸ¥è©¢æ—¥èªŒ
        """
        query = self._build_logql_query(service, namespace, log_level, pattern)
        end_time = datetime.now(timezone.utc)
        start_time = end_time - timedelta(minutes=time_range)
        
        params = {
            "query": query,
            "start": str(int(start_time.timestamp() * 1e9)),
            "end": str(int(end_time.timestamp() * 1e9)),
            "limit": limit,
            "direction": "backward"
        }

        response = await self.http_client.get(f"{self.base_url}/loki/api/v1/query_range", params=params, timeout=self.timeout)
        response.raise_for_status()
        data = response.json()

        if data.get("status") != "success":
            error_msg = data.get('error', 'Unknown Loki query error')
            logger.warning(f"Loki æŸ¥è©¢æˆåŠŸä½†èªæ³•æˆ–åŸ·è¡Œå¤±æ•—: {error_msg}")
            return []

        return self._parse_log_results(data.get("data", {}).get("result", []))
    
    def _build_logql_query(self, service: str, namespace: str, log_level: str, pattern: str) -> str:
        """
        å»ºæ§‹ LogQL æŸ¥è©¢èªå¥
        """
        selectors = []
        if service: selectors.append(f'app="{service}"')
        if namespace: selectors.append(f'namespace="{namespace}"')
        if not selectors: selectors.append('job=~".+"')
        query = "{" + ",".join(selectors) + "}"
        
        if log_level and log_level.lower() != "all":
            level_patterns = {
                "error": "(?i)(error|err|fatal|panic|critical)",
                "warn": "(?i)(warn|warning)",
                "info": "(?i)(info|information)",
                "debug": "(?i)(debug|trace)"
            }
            if log_level.lower() in level_patterns:
                query += f' |~ "{level_patterns[log_level.lower()]}"'
        
        if pattern: query += f' |~ "{pattern}"'
        return query
    
    def _parse_log_results(self, results: List[Dict]) -> List[Dict[str, Any]]:
        """
        è§£æ Loki æŸ¥è©¢çµæœ
        """
        logs = []
        for stream in results:
            stream_labels = stream.get("stream", {})
            for value in stream.get("values", []):
                if len(value) >= 2:
                    logs.append({
                        "timestamp": datetime.fromtimestamp(int(value[0]) / 1e9, tz=timezone.utc).isoformat(),
                        "labels": stream_labels,
                        "message": value[1],
                        "parsed": self._parse_log_line(value[1])
                    })
        logs.sort(key=lambda x: x["timestamp"], reverse=True)
        return logs
    
    def _parse_log_line(self, log_line: str) -> Dict[str, Any]:
        """
        è§£æå–®è¡Œæ—¥èªŒ
        """
        try:
            return json.loads(log_line)
        except json.JSONDecodeError:
            return {"raw": log_line, "level": self._extract_log_level(log_line), "error_type": self._extract_error_type(log_line)}
    
    def _extract_log_level(self, log_line: str) -> str:
        """æå–æ—¥èªŒç´šåˆ¥"""
        log_line_lower = log_line.lower()
        if any(word in log_line_lower for word in ["error", "err", "fatal", "panic", "critical"]): return "ERROR"
        if any(word in log_line_lower for word in ["warn", "warning"]): return "WARN"
        if any(word in log_line_lower for word in ["info", "information"]): return "INFO"
        if any(word in log_line_lower for word in ["debug", "trace"]): return "DEBUG"
        return "UNKNOWN"
    
    def _extract_error_type(self, log_line: str) -> Optional[str]:
        """æå–éŒ¯èª¤é¡å‹"""
        error_patterns = {"OOMKilled": "è¨˜æ†¶é«”ä¸è¶³", "Connection refused": "é€£æ¥è¢«æ‹’çµ•", "Connection timeout": "é€£æ¥è¶…æ™‚", "NullPointerException": "ç©ºæŒ‡æ¨™ç•°å¸¸", "StackOverflowError": "å †ç–Šæº¢å‡º", "OutOfMemoryError": "è¨˜æ†¶é«”ä¸è¶³", "DeadlockDetected": "æ­»é–åµæ¸¬", "Circuit breaker": "ç†”æ–·å™¨è§¸ç™¼", "Rate limit": "é€Ÿç‡é™åˆ¶", "401": "æœªæˆæ¬Š", "403": "ç¦æ­¢è¨ªå•", "404": "è³‡æºæœªæ‰¾åˆ°", "500": "å…§éƒ¨ä¼ºæœå™¨éŒ¯èª¤", "502": "é–˜é“éŒ¯èª¤", "503": "æœå‹™ä¸å¯ç”¨", "504": "é–˜é“è¶…æ™‚"}
        for pattern, error_type in error_patterns.items():
            if pattern in log_line: return error_type
        return None
    
    def _analyze_logs(self, logs: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        åˆ†ææ—¥èªŒæ¨¡å¼å’Œçµ±è¨ˆ
        """
        if not logs: return {"total_logs": 0, "level_distribution": {}, "error_types": {}, "top_errors": []}
        
        level_counts, error_types, error_messages = {}, {}, []
        for log in logs:
            level = log.get("parsed", {}).get("level", "UNKNOWN")
            level_counts[level] = level_counts.get(level, 0) + 1
            error_type = log.get("parsed", {}).get("error_type")
            if error_type: error_types[error_type] = error_types.get(error_type, 0) + 1
            if level == "ERROR": error_messages.append(log.get("message", ""))
        
        top_errors = []
        if error_messages:
            error_clusters = self._cluster_errors(error_messages)
            top_errors = sorted(error_clusters.items(), key=lambda x: x[1], reverse=True)[:5]
        
        return {"total_logs": len(logs), "level_distribution": level_counts, "error_types": error_types, "top_errors": [{"pattern": pattern, "count": count} for pattern, count in top_errors], "critical_indicators": self._identify_critical_indicators(logs)}
    
    def _cluster_errors(self, error_messages: List[str]) -> Dict[str, int]:
        """
        ç°¡å–®çš„éŒ¯èª¤èšé¡
        """
        clusters = {}
        for message in error_messages:
            key_parts = []
            exception_words = re.findall(r'\b\w*Exception\b', message)
            if exception_words: key_parts.append(max(exception_words, key=len))
            error_codes = re.findall(r'\b[4-5]\d{2}\b', message)
            if error_codes: key_parts.extend(error_codes)
            if not key_parts: key_parts.append(message.splitlines()[0][:50])
            cluster_key = " | ".join(sorted(list(set(key_parts))))
            clusters[cluster_key] = clusters.get(cluster_key, 0) + 1
        return clusters
    
    def _identify_critical_indicators(self, logs: List[Dict[str, Any]]) -> List[str]:
        """
        è­˜åˆ¥é—œéµæŒ‡æ¨™
        """
        indicators = []
        if sum(1 for log in logs if "OOMKilled" in log.get("message", "")) > 0: indicators.append(f"ç™¼ç¾ {sum(1 for log in logs if 'OOMKilled' in log.get('message', ''))} æ¬¡è¨˜æ†¶é«”ä¸è¶³éŒ¯èª¤ (OOMKilled)")
        if sum(1 for log in logs if "panic" in log.get("message", "").lower()) > 0: indicators.append(f"ç™¼ç¾ {sum(1 for log in logs if 'panic' in log.get('message', '').lower())} æ¬¡ Panic éŒ¯èª¤")
        conn_errors = sum(1 for log in logs if any(p in log.get("message", "") for p in ["Connection refused", "Connection timeout", "connection reset"]))
        if conn_errors > 5: indicators.append(f"ç™¼ç¾ {conn_errors} æ¬¡é€£æ¥éŒ¯èª¤ï¼Œå¯èƒ½å­˜åœ¨ç¶²è·¯å•é¡Œ")
        error_logs = sum(1 for log in logs if log.get("parsed", {}).get("level") == "ERROR")
        if len(logs) > 0 and (error_logs / len(logs)) * 100 > 50: indicators.append(f"éŒ¯èª¤ç‡éé«˜: {(error_logs / len(logs)) * 100:.1f}%")
        return indicators
