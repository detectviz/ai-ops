# services/sre-assistant/src/sre_assistant/tools/prometheus_tool.py
"""
Prometheus æŸ¥è©¢å·¥å…·
ç”¨æ–¼æŸ¥è©¢æœå‹™çš„é—œéµæŒ‡æ¨™ï¼ˆå››å¤§é»ƒé‡‘è¨Šè™Ÿï¼‰
"""

import structlog
import httpx
import json
from typing import Dict, Any, Optional, List
from datetime import datetime, timezone
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception, RetryError

from ..contracts import ToolResult, ToolError

logger = structlog.get_logger(__name__)


def should_retry_prometheus_exception(exception: BaseException) -> bool:
    """
    æ±ºå®šæ˜¯å¦æ‡‰é‡è©¦ Prometheus è«‹æ±‚çš„è‡ªè¨‚é‚è¼¯ã€‚

    - å°æ–¼é€£ç·šéŒ¯èª¤å’Œè¶…æ™‚ï¼Œç¸½æ˜¯é‡è©¦ã€‚
    - å°æ–¼ HTTP ç‹€æ…‹éŒ¯èª¤ï¼Œåƒ…å° 5xx ç³»åˆ—çš„ä¼ºæœå™¨éŒ¯èª¤é‡è©¦ã€‚
    - å°æ–¼å…¶ä»–éŒ¯èª¤ï¼ˆå¦‚ 4xx å®¢æˆ¶ç«¯éŒ¯èª¤ï¼‰ï¼Œä¸é‡è©¦ã€‚
    """
    if isinstance(exception, (httpx.TimeoutException, httpx.ConnectError)):
        return True
    if isinstance(exception, httpx.HTTPStatusError):
        # åƒ…å° 5xx (ä¼ºæœå™¨éŒ¯èª¤) æˆ– 429 (è«‹æ±‚éå¤š) é‡è©¦
        return exception.response.status_code >= 500 or exception.response.status_code == 429
    return False


class PrometheusQueryTool:
    """
    Prometheus æŸ¥è©¢å·¥å…·
    
    å¯¦ä½œ SRE å››å¤§é»ƒé‡‘è¨Šè™ŸæŸ¥è©¢ï¼š
    - Latency (å»¶é²)
    - Traffic (æµé‡)
    - Errors (éŒ¯èª¤)
    - Saturation (é£½å’Œåº¦)
    """
    
    def __init__(self, config, http_client: httpx.AsyncClient, redis_client=None):
        """
        åˆå§‹åŒ– Prometheus å·¥å…·

        Args:
            config: æ‡‰ç”¨ç¨‹å¼è¨­å®šç‰©ä»¶ã€‚
            http_client: ä¸€å€‹å…±äº«çš„ httpx.AsyncClient å¯¦ä¾‹ã€‚
            redis_client: éåŒæ­¥ Redis å®¢æˆ¶ç«¯ï¼Œç”¨æ–¼å¿«å–ã€‚
        """
        self.base_url = config.prometheus.base_url
        self.timeout = config.prometheus.timeout_seconds
        self.default_step = config.prometheus.default_step
        self.max_points = config.prometheus.max_points
        self.http_client = http_client
        
        # å¿«å–è¨­å®š
        self.redis_client = redis_client
        self.cache_ttl_seconds = config.prometheus.get("cache_ttl_seconds", 300) # é è¨­ 5 åˆ†é˜

        # é‡è©¦è¨­å®š
        self.max_retries = config.workflow.get("max_retries", 2)
        self.retry_wait_multiplier = config.workflow.get("retry_delay_seconds", 1)

        logger.info(
            f"âœ… Prometheus å·¥å…·åˆå§‹åŒ– (ä½¿ç”¨å…±äº« HTTP å®¢æˆ¶ç«¯): {self.base_url}",
            max_retries=self.max_retries,
            retry_wait_multiplier=self.retry_wait_multiplier
        )
    
    async def execute(self, params: Dict[str, Any]) -> ToolResult:
        """
        åŸ·è¡Œ Prometheus æŸ¥è©¢
        
        Args:
            params: åŒ…å«æŸ¥è©¢åƒæ•¸çš„å­—å…¸
                - service: æœå‹™åç¨±
                - namespace: å‘½åç©ºé–“
                - metric_type: æŒ‡æ¨™é¡å‹ (latency/traffic/errors/saturation)
                - time_range: æ™‚é–“ç¯„åœï¼ˆåˆ†é˜ï¼‰
                
        Returns:
            ToolResult åŒ…å«æŸ¥è©¢çµæœæˆ–éŒ¯èª¤
        """
        try:
            service = params.get("service", "")
            namespace = params.get("namespace", "default")
            metric_type = params.get("metric_type", "all")
            time_range = params.get("time_range", 30)  # é è¨­ 30 åˆ†é˜
            
            logger.info(f"ğŸ“Š æŸ¥è©¢ Prometheus: service={service}, namespace={namespace}, type={metric_type}")
            
            # å„ªå…ˆè™•ç†è‡ªå®šç¾©æŸ¥è©¢
            query = params.get("query")
            if query:
                metrics = await self._query_custom(query, time_range)
            # å¦å‰‡ï¼Œæ ¹æ“šæŒ‡æ¨™é¡å‹åŸ·è¡ŒæŸ¥è©¢
            elif metric_type == "all":
                metrics = await self.query_golden_signals(service, namespace, time_range)
            elif metric_type == "latency":
                metrics = await self._query_latency(service, namespace, time_range)
            elif metric_type == "traffic":
                metrics = await self._query_traffic(service, namespace, time_range)
            elif metric_type == "errors":
                metrics = await self._query_errors(service, namespace, time_range)
            elif metric_type == "saturation":
                metrics = await self._query_saturation(service, namespace, time_range)
            else:
                # ä¿ç•™ä¸€å€‹å¾Œå‚™ï¼Œå„˜ç®¡åœ¨ä¸Šé¢çš„é‚è¼¯ä¸­ä¸å¤ªå¯èƒ½åˆ°é”
                metrics = {"error": f"æœªçŸ¥æŒ‡æ¨™é¡å‹: {metric_type}"}
            
            return ToolResult(
                success=True,
                data=metrics,
                metadata={
                    "source": "prometheus",
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "query_time_range": f"{time_range}m"
                }
            )
            
        except RetryError as e:
            logger.error(f"âŒ Prometheus API æŸ¥è©¢åœ¨é‡è©¦å¾Œä»ç„¶å¤±æ•—: {e}", exc_info=True)
            original_exception = e.last_attempt.exception()

            error_code = "RETRY_ERROR"
            error_message = "Request failed after multiple retries."
            details = {"last_exception": str(original_exception)}

            if isinstance(original_exception, httpx.HTTPStatusError):
                error_code = "HTTP_STATUS_ERROR"
                error_message = f"Prometheus API returned HTTP {original_exception.response.status_code}: {original_exception.response.reason_phrase}"
                details = {
                    "status_code": original_exception.response.status_code,
                    "response_body": original_exception.response.text[:500],
                    "request_url": str(original_exception.request.url),
                }
            elif isinstance(original_exception, httpx.TimeoutException):
                error_code = "TIMEOUT_ERROR"
                error_message = f"Prometheus API request timed out after {self.timeout}s"
                details = {
                    "timeout_seconds": self.timeout,
                    "request_url": str(original_exception.request.url) if hasattr(original_exception, 'request') else None,
                }
            elif isinstance(original_exception, httpx.ConnectError):
                error_code = "CONNECTION_ERROR"
                error_message = f"Failed to connect to Prometheus: {str(original_exception)}"
                details = {"base_url": self.base_url}

            details["params"] = params
            details["retries"] = self.max_retries

            return ToolResult(
                success=False,
                error=ToolError(code=error_code, message=error_message, details=details)
            )
        except httpx.HTTPStatusError as e:
            # åªæœ‰åœ¨ tenacity ä¸é‡è©¦æ™‚ (ä¾‹å¦‚ 4xx éŒ¯èª¤) æ‰æœƒç›´æ¥è§¸ç™¼é€™è£¡
            logger.error(f"âŒ Prometheus API æŸ¥è©¢å¤±æ•— (éé‡è©¦): {e.response.status_code} - {e.response.text}", exc_info=True)
            return ToolResult(
                success=False,
                error=ToolError(
                    code="HTTP_STATUS_ERROR",
                    message=f"Prometheus API returned HTTP {e.response.status_code}: {e.response.reason_phrase}",
                    details={
                        "status_code": e.response.status_code,
                        "response_body": e.response.text[:500],
                        "request_url": str(e.request.url),
                        "params": params
                    }
                )
            )
        except httpx.TimeoutException as e:
            logger.error(f"âŒ Prometheus API è«‹æ±‚è¶…æ™‚: {e}", exc_info=True)
            return ToolResult(
                success=False,
                error=ToolError(
                    code="TIMEOUT_ERROR",
                    message=f"Prometheus API request timed out after {self.timeout}s",
                    details={
                        "timeout_seconds": self.timeout,
                        "request_url": str(e.request.url) if hasattr(e, 'request') else None,
                        "params": params
                    }
                )
            )
        except httpx.ConnectError as e:
            logger.error(f"âŒ Prometheus API é€£ç·šå¤±æ•—: {e}", exc_info=True)
            return ToolResult(
                success=False,
                error=ToolError(
                    code="CONNECTION_ERROR",
                    message=f"Failed to connect to Prometheus: {str(e)}",
                    details={
                        "base_url": self.base_url,
                        "params": params
                    }
                )
            )
        except Exception as e:
            logger.error(f"âŒ Prometheus å·¥å…·åŸ·è¡Œæ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}", exc_info=True)
            return ToolResult(
                success=False,
                error=ToolError(
                    code="UNEXPECTED_ERROR",
                    message=f"Unexpected error in Prometheus tool: {str(e)}",
                    details={
                        "error_type": type(e).__name__,
                        "params": params
                    }
                )
            )
    
    async def query_golden_signals(self, service_name: str, namespace: str, duration: str) -> Dict[str, Any]:
        """æŸ¥è©¢å››å¤§é»ƒé‡‘è¨Šè™Ÿ"""
        results = {}
        
        # ä¸¦è¡ŒæŸ¥è©¢æ‰€æœ‰æŒ‡æ¨™
        import asyncio
        tasks = [
            self._query_latency(service_name, namespace, duration),
            self._query_traffic(service_name, namespace, duration),
            self._query_errors(service_name, namespace, duration),
            self._query_saturation(service_name, namespace, duration)
        ]
        
        latency, traffic, errors, saturation = await asyncio.gather(*tasks, return_exceptions=True)
        
        # è™•ç†çµæœ
        if not isinstance(latency, Exception):
            results["latency"] = latency
        if not isinstance(traffic, Exception):
            results["traffic"] = traffic
        if not isinstance(errors, Exception):
            results["errors"] = errors
        if not isinstance(saturation, Exception):
            results["saturation"] = saturation
        
        return results
    
    async def _query_latency(self, service: str, namespace: str, time_range: int) -> Dict[str, Any]:
        """æŸ¥è©¢å»¶é²æŒ‡æ¨™"""
        # P50, P95, P99 å»¶é²
        queries = {
            "p50": f'histogram_quantile(0.50, rate(http_request_duration_seconds_bucket{{service="{service}", namespace="{namespace}"}}[5m]))',
            "p95": f'histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{{service="{service}", namespace="{namespace}"}}[5m]))',
            "p99": f'histogram_quantile(0.99, rate(http_request_duration_seconds_bucket{{service="{service}", namespace="{namespace}"}}[5m]))'
        }
        
        results = {}
        for percentile, query in queries.items():
            value = await self._execute_instant_query(query)
            if value is not None:
                results[percentile] = f"{value*1000:.2f}ms"
        
        return results
    
    async def _query_traffic(self, service: str, namespace: str, time_range: int) -> Dict[str, Any]:
        """æŸ¥è©¢æµé‡æŒ‡æ¨™"""
        # è«‹æ±‚ç‡ (RPS)
        query = f'sum(rate(http_requests_total{{service="{service}", namespace="{namespace}"}}[5m]))'
        
        rps = await self._execute_instant_query(query)
        
        return {
            "requests_per_second": round(rps, 2) if rps else 0,
            "requests_per_minute": round(rps * 60, 2) if rps else 0
        }
    
    async def _query_errors(self, service: str, namespace: str, time_range: int) -> Dict[str, Any]:
        """æŸ¥è©¢éŒ¯èª¤æŒ‡æ¨™"""
        # éŒ¯èª¤ç‡
        error_query = f'sum(rate(http_requests_total{{service="{service}", namespace="{namespace}", status=~"5.."}}[5m]))'
        total_query = f'sum(rate(http_requests_total{{service="{service}", namespace="{namespace}"}}[5m]))'
        
        errors = await self._execute_instant_query(error_query)
        total = await self._execute_instant_query(total_query)
        
        error_rate = 0
        if total and total > 0:
            error_rate = (errors / total) * 100
        
        return {
            "error_rate": f"{error_rate:.2f}%",
            "errors_per_minute": round(errors * 60, 2) if errors else 0
        }
    
    async def _query_saturation(self, service: str, namespace: str, time_range: int) -> Dict[str, Any]:
        """æŸ¥è©¢é£½å’Œåº¦æŒ‡æ¨™"""
        queries = {
            "cpu_usage": f'avg(rate(container_cpu_usage_seconds_total{{pod=~"{service}.*", namespace="{namespace}"}}[5m])) * 100',
            "memory_usage": f'avg(container_memory_usage_bytes{{pod=~"{service}.*", namespace="{namespace}"}}) / avg(container_spec_memory_limit_bytes{{pod=~"{service}.*", namespace="{namespace}"}}) * 100',
            "disk_usage": f'avg(container_fs_usage_bytes{{pod=~"{service}.*", namespace="{namespace}"}}) / avg(container_fs_limit_bytes{{pod=~"{service}.*", namespace="{namespace}"}}) * 100'
        }
        
        results = {}
        for metric, query in queries.items():
            value = await self._execute_instant_query(query)
            if value is not None:
                results[metric] = f"{value:.2f}%"
        
        # æŸ¥è©¢ Pod æ•¸é‡
        pod_query = f'count(up{{job="{service}", namespace="{namespace}"}})'
        pod_count = await self._execute_instant_query(pod_query)
        results["pod_count"] = int(pod_count) if pod_count else 0
        
        return results
    
    async def _query_custom(self, query: str, time_range: int) -> Dict[str, Any]:
        """åŸ·è¡Œè‡ªå®šç¾©æŸ¥è©¢"""
        if not query:
            return {"error": "No query provided"}
        
        value = await self._execute_instant_query(query)
        return {"value": value, "query": query}
    
    async def check_health(self) -> bool:
        """
        åŸ·è¡Œå° Prometheus çš„å¥åº·æª¢æŸ¥ã€‚

        Returns:
            å¦‚æœ Prometheus å¯é”ä¸”å¥åº·ï¼Œå‰‡è¿”å› Trueï¼Œå¦å‰‡è¿”å› Falseã€‚
        """
        try:
            response = await self.http_client.get(f"{self.base_url}/-/healthy", timeout=self.timeout)
            response.raise_for_status()
            logger.debug(f"Prometheus health check successful: {response.status_code}")
            return True
        except (httpx.HTTPStatusError, httpx.RequestError) as e:
            logger.warning(f"Prometheus health check failed: {e}")
            return False

    async def _execute_with_retry(self, request_func, **kwargs):
        """
        ä¸€å€‹é€šç”¨çš„åŒ…è£å‡½å¼ï¼Œä»¥ç¨‹å¼åŒ–çš„æ–¹å¼åŸ·è¡Œå…·æœ‰ tenacity é‡è©¦é‚è¼¯çš„è«‹æ±‚ã€‚
        é€™å…è¨±æˆ‘å€‘ä½¿ç”¨ä¾†è‡ª 'self' çš„é…ç½® (ä¾‹å¦‚ self.max_retries)ã€‚
        """
        retry_decorator = retry(
            stop=stop_after_attempt(self.max_retries + 1),
            wait=wait_exponential(multiplier=self.retry_wait_multiplier, min=2, max=10),
            retry=retry_if_exception(should_retry_prometheus_exception),
            reraise=True
        )
        return await retry_decorator(request_func)(**kwargs)

    async def _execute_instant_query(self, query: str) -> Optional[float]:
        """
        åŸ·è¡Œå³æ™‚æŸ¥è©¢ï¼Œä¸¦å¢åŠ  Redis å¿«å–æ©Ÿåˆ¶ã€‚
        """
        cache_key = f"prometheus:instant:{query}"

        if self.redis_client:
            try:
                cached_result = await self.redis_client.get(cache_key)
                if cached_result:
                    logger.info(f"CACHE HIT: å¾ Redis ç²å–å³æ™‚æŸ¥è©¢çµæœ: {query}")
                    data = json.loads(cached_result)
                    return float(data) if data is not None else None
            except Exception as e:
                logger.error(f"Redis å¿«å–è®€å–å¤±æ•—: {e}")

        async def do_request():
            params = {"query": query, "time": datetime.now(timezone.utc).isoformat()}
            response = await self.http_client.get(
                f"{self.base_url}/api/v1/query",
                params=params,
                timeout=self.timeout
            )
            response.raise_for_status()
            return response.json()

        data = await self._execute_with_retry(do_request)

        if data["status"] != "success":
            logger.warning(f"Prometheus æŸ¥è©¢ '{query}' æˆåŠŸåŸ·è¡Œä½†æœªè¿”å› 'success' ç‹€æ…‹: {data.get('error', 'Unknown error')}")
            return None

        value_to_cache = None
        results = data.get("data", {}).get("result", [])
        if results and len(results) > 0:
            value = results[0].get("value", [])
            if len(value) > 1:
                value_to_cache = float(value[1])

        if self.redis_client and value_to_cache is not None:
            try:
                await self.redis_client.set(
                    cache_key,
                    json.dumps(value_to_cache),
                    ex=self.cache_ttl_seconds,
                )
                logger.info(f"CACHE SET: å·²å¿«å–å³æ™‚æŸ¥è©¢çµæœ: {query}")
            except Exception as e:
                logger.error(f"Redis å¿«å–å¯«å…¥å¤±æ•—: {e}")

        return value_to_cache
    
    async def _execute_range_query(self, query: str, start: datetime, end: datetime, step: str = "1m") -> List[Dict]:
        """
        åŸ·è¡Œç¯„åœæŸ¥è©¢ï¼Œä¸¦å¢åŠ  Redis å¿«å–æ©Ÿåˆ¶ã€‚
        """
        start_key = start.strftime('%Y-%m-%dT%H:%M')
        end_key = end.strftime('%Y-%m-%dT%H:%M')
        cache_key = f"prometheus:range:{query}:{start_key}:{end_key}:{step}"

        if self.redis_client:
            try:
                cached_result = await self.redis_client.get(cache_key)
                if cached_result:
                    logger.info(f"CACHE HIT: å¾ Redis ç²å–ç¯„åœæŸ¥è©¢çµæœ: {query}")
                    return json.loads(cached_result)
            except Exception as e:
                logger.error(f"Redis å¿«å–è®€å–å¤±æ•—: {e}")

        async def do_request():
            params = {
                "query": query,
                "start": start.isoformat(),
                "end": end.isoformat(),
                "step": step
            }
            response = await self.http_client.get(
                f"{self.base_url}/api/v1/query_range",
                params=params,
                timeout=self.timeout
            )
            response.raise_for_status()
            return response.json()

        data = await self._execute_with_retry(do_request)

        if data["status"] != "success":
            logger.warning(f"Prometheus æŸ¥è©¢ '{query}' æˆåŠŸåŸ·è¡Œä½†æœªè¿”å› 'success' ç‹€æ…‹: {data.get('error', 'Unknown error')}")
            return []

        result_to_cache = data.get("data", {}).get("result", [])

        if self.redis_client and result_to_cache:
            try:
                await self.redis_client.set(
                    cache_key,
                    json.dumps(result_to_cache),
                    ex=self.cache_ttl_seconds,
                )
                logger.info(f"CACHE SET: å·²å¿«å–ç¯„åœæŸ¥è©¢çµæœ: {query}")
            except Exception as e:
                logger.error(f"Redis å¿«å–å¯«å…¥å¤±æ•—: {e}")

        return result_to_cache
