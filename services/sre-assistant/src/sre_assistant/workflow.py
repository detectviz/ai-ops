# services/sre-assistant/src/sre_assistant/workflow.py
"""
SRE å·¥ä½œæµç¨‹å”èª¿å™¨
è² è²¬å”èª¿å„ç¨®è¨ºæ–·å·¥å…·ä¸¦æ•´åˆçµæœ
"""

import asyncio
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime, timezone
import json

from .contracts import (
    SRERequest,
    ToolResult,
    ToolError,
    Finding,
    SeverityLevel
)
from .tools.prometheus_tool import PrometheusQueryTool
from .tools.loki_tool import LokiLogQueryTool
from .tools.control_plane_tool import ControlPlaneTool

logger = logging.getLogger(__name__)


class SREWorkflow:
    """
    ä¸»è¦çš„ SRE å·¥ä½œæµç¨‹å”èª¿å™¨
    
    è² è²¬ï¼š
    1. æ¥æ”¶è¨ºæ–·è«‹æ±‚
    2. ä¸¦è¡ŒåŸ·è¡Œå¤šå€‹è¨ºæ–·å·¥å…·
    3. æ•´åˆåˆ†æçµæœ
    4. ç”Ÿæˆè¨ºæ–·å ±å‘Š
    """
    
    def __init__(self, config):
        """åˆå§‹åŒ–å·¥ä½œæµç¨‹"""
        self.config = config
        
        # åˆå§‹åŒ–å·¥å…·
        self.prometheus_tool = PrometheusQueryTool(config)
        self.loki_tool = LokiLogQueryTool(config)
        self.control_plane_tool = ControlPlaneTool(config)
        
        # å·¥ä½œæµç¨‹è¨­å®š
        self.parallel_diagnosis = config.workflow.get("parallel_diagnosis", True)
        self.diagnosis_timeout = config.workflow.get("diagnosis_timeout_seconds", 60)
        
        logger.info("âœ… SRE å·¥ä½œæµç¨‹åˆå§‹åŒ–å®Œæˆ")
    
    async def execute(self, request: SRERequest) -> Dict[str, Any]:
        """
        åŸ·è¡Œä¸»è¦å·¥ä½œæµç¨‹
        
        Args:
            request: SRE è«‹æ±‚ç‰©ä»¶
            
        Returns:
            åŒ…å«è¨ºæ–·çµæœçš„å­—å…¸
        """
        start_time = datetime.now(timezone.utc)
        logger.info(f"ğŸš€ é–‹å§‹åŸ·è¡Œå·¥ä½œæµç¨‹: {request.incident_id}")
        
        try:
            # æ ¹æ“šè«‹æ±‚é¡å‹æ±ºå®šåŸ·è¡Œç­–ç•¥
            context_type = request.context.get("type", "unknown")
            
            if context_type == "deployment_diagnosis":
                result = await self._diagnose_deployment(request)
            elif context_type == "alert_diagnosis":
                result = await self._diagnose_alerts(request)
            elif context_type == "ad_hoc_query":
                result = await self._execute_ad_hoc_query(request)
            else:
                result = await self._generic_diagnosis(request)
            
            # è¨ˆç®—åŸ·è¡Œæ™‚é–“
            execution_time_ms = int((datetime.now(timezone.utc) - start_time).total_seconds() * 1000)
            result["execution_time_ms"] = execution_time_ms
            
            logger.info(f"âœ… å·¥ä½œæµç¨‹å®Œæˆ: {request.incident_id} (è€—æ™‚ {execution_time_ms}ms)")
            return result
            
        except Exception as e:
            logger.error(f"âŒ å·¥ä½œæµç¨‹åŸ·è¡Œå¤±æ•—: {e}")
            return {
                "status": "FAILED",
                "summary": f"è¨ºæ–·éç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}",
                "findings": [],
                "recommended_action": "è«‹è¯ç¹«ç³»çµ±ç®¡ç†å“¡",
                "confidence_score": 0.0
            }
    
    async def _diagnose_deployment(self, request: SRERequest) -> Dict[str, Any]:
        """
        è¨ºæ–·éƒ¨ç½²å•é¡Œ
        
        åŸ·è¡Œä¸¦è¡Œè¨ºæ–·ï¼š
        1. æŸ¥è©¢ Prometheus æŒ‡æ¨™
        2. æŸ¥è©¢ Loki æ—¥èªŒ
        3. æŸ¥è©¢ Control Plane è®Šæ›´æ­·å²
        """
        logger.info(f"ğŸ” è¨ºæ–·éƒ¨ç½²: {request.context.get('service_name')}")
        
        # æº–å‚™è¨ºæ–·ä»»å‹™
        tasks = []
        
        # 1. Prometheus æŒ‡æ¨™æŸ¥è©¢
        prometheus_task = self._query_metrics(
            service=request.context.get("service_name"),
            namespace=request.context.get("namespace", "default")
        )
        tasks.append(("prometheus", prometheus_task))
        
        # 2. Loki æ—¥èªŒæŸ¥è©¢
        loki_task = self._query_logs(
            service=request.context.get("service_name"),
            namespace=request.context.get("namespace", "default")
        )
        tasks.append(("loki", loki_task))
        
        # 3. Control Plane å¯©è¨ˆæ—¥èªŒ
        audit_task = self._query_audit_logs(
            service=request.context.get("service_name")
        )
        tasks.append(("audit", audit_task))
        
        # ä¸¦è¡ŒåŸ·è¡Œæ‰€æœ‰è¨ºæ–·
        if self.parallel_diagnosis:
            results = await self._execute_parallel_tasks(tasks)
        else:
            results = await self._execute_sequential_tasks(tasks)
        
        # åˆ†æçµæœä¸¦ç”Ÿæˆå ±å‘Š
        return self._analyze_deployment_results(results, request)
    
    async def _diagnose_alerts(self, request: SRERequest) -> Dict[str, Any]:
        """è¨ºæ–·å‘Šè­¦äº‹ä»¶"""
        logger.info(f"ğŸš¨ è¨ºæ–·å‘Šè­¦: {request.context.get('incident_ids')}")
        
        # TODO: å¯¦ä½œå‘Šè­¦è¨ºæ–·é‚è¼¯
        findings = []
        
        # æ¨¡æ“¬è¨ºæ–·çµæœ
        findings.append(Finding(
            source="AlertManager",
            severity=SeverityLevel.P1,
            data={
                "alert_count": len(request.context.get("incident_ids", [])),
                "pattern": "å¤šå€‹æœå‹™åŒæ™‚å‘Šè­¦ï¼Œå¯èƒ½æ˜¯åŸºç¤è¨­æ–½å•é¡Œ"
            }
        ))
        
        return {
            "status": "COMPLETED",
            "summary": f"åˆ†æäº† {len(request.context.get('incident_ids', []))} å€‹å‘Šè­¦äº‹ä»¶",
            "findings": [f.dict() for f in findings],
            "recommended_action": "æª¢æŸ¥åŸºç¤è¨­æ–½ç‹€æ…‹",
            "confidence_score": 0.75
        }
    
    async def _execute_ad_hoc_query(self, request: SRERequest) -> Dict[str, Any]:
        """åŸ·è¡Œè‡¨æ©ŸæŸ¥è©¢"""
        logger.info(f"ğŸ’¬ åŸ·è¡ŒæŸ¥è©¢: {request.input[:50]}...")
        
        # TODO: æ•´åˆ LLM é€²è¡Œè‡ªç„¶èªè¨€ç†è§£å’Œå·¥å…·é¸æ“‡
        
        return {
            "status": "COMPLETED",
            "summary": "æŸ¥è©¢åŸ·è¡Œå®Œæˆ",
            "findings": [],
            "recommended_action": None,
            "confidence_score": 0.7
        }
    
    async def _generic_diagnosis(self, request: SRERequest) -> Dict[str, Any]:
        """é€šç”¨è¨ºæ–·æµç¨‹"""
        logger.info(f"ğŸ”§ åŸ·è¡Œé€šç”¨è¨ºæ–·: {request.incident_id}")
        
        return {
            "status": "COMPLETED",
            "summary": "é€šç”¨è¨ºæ–·å®Œæˆ",
            "findings": [],
            "recommended_action": "è«‹æä¾›æ›´å¤šä¸Šä¸‹æ–‡è³‡è¨Š",
            "confidence_score": 0.5
        }
    
    # === å·¥å…·æŸ¥è©¢æ–¹æ³• ===
    
    async def _query_metrics(self, service: str, namespace: str) -> ToolResult:
        """æŸ¥è©¢ Prometheus æŒ‡æ¨™"""
        try:
            # TODO: å¯¦ä½œå¯¦éš›çš„ Prometheus æŸ¥è©¢
            await asyncio.sleep(0.5)  # æ¨¡æ“¬æŸ¥è©¢å»¶é²
            
            return ToolResult(
                success=True,
                data={
                    "cpu_usage": "85%",
                    "memory_usage": "92%",
                    "error_rate": "0.05",
                    "latency_p99": "1500ms"
                }
            )
        except Exception as e:
            return ToolResult(
                success=False,
                error=ToolError(code="PROMETHEUS_ERROR", message=str(e))
            )
    
    async def _query_logs(self, service: str, namespace: str) -> ToolResult:
        """æŸ¥è©¢ Loki æ—¥èªŒ"""
        try:
            # TODO: å¯¦ä½œå¯¦éš›çš„ Loki æŸ¥è©¢
            await asyncio.sleep(0.3)  # æ¨¡æ“¬æŸ¥è©¢å»¶é²
            
            return ToolResult(
                success=True,
                data={
                    "error_count": 42,
                    "critical_errors": ["OOMKilled", "Connection timeout"],
                    "log_volume": "high"
                }
            )
        except Exception as e:
            return ToolResult(
                success=False,
                error=ToolError(code="LOKI_ERROR", message=str(e))
            )
    
    async def _query_audit_logs(self, service: str) -> ToolResult:
        """æŸ¥è©¢å¯©è¨ˆæ—¥èªŒ"""
        try:
            # TODO: å¯¦ä½œå¯¦éš›çš„ Control Plane API èª¿ç”¨
            await asyncio.sleep(0.2)  # æ¨¡æ“¬æŸ¥è©¢å»¶é²
            
            return ToolResult(
                success=True,
                data={
                    "recent_changes": [
                        {
                            "time": "2025-01-02T10:30:00Z",
                            "user": "admin",
                            "action": "UPDATE_CONFIG",
                            "details": "Modified resource limits"
                        }
                    ]
                }
            )
        except Exception as e:
            return ToolResult(
                success=False,
                error=ToolError(code="AUDIT_ERROR", message=str(e))
            )
    
    # === è¼”åŠ©æ–¹æ³• ===
    
    async def _execute_parallel_tasks(self, tasks: List[tuple]) -> Dict[str, ToolResult]:
        """ä¸¦è¡ŒåŸ·è¡Œè¨ºæ–·ä»»å‹™"""
        results = {}
        
        # å»ºç«‹ç•°æ­¥ä»»å‹™
        async_tasks = []
        for name, task in tasks:
            async_tasks.append((name, asyncio.create_task(task)))
        
        # ç­‰å¾…æ‰€æœ‰ä»»å‹™å®Œæˆ
        for name, task in async_tasks:
            try:
                result = await asyncio.wait_for(task, timeout=self.diagnosis_timeout)
                results[name] = result
            except asyncio.TimeoutError:
                logger.warning(f"â±ï¸ ä»»å‹™ {name} è¶…æ™‚")
                results[name] = ToolResult(
                    success=False,
                    error=ToolError(code="TIMEOUT", message=f"ä»»å‹™ {name} åŸ·è¡Œè¶…æ™‚")
                )
        
        return results
    
    async def _execute_sequential_tasks(self, tasks: List[tuple]) -> Dict[str, ToolResult]:
        """å¾ªåºåŸ·è¡Œè¨ºæ–·ä»»å‹™"""
        results = {}
        
        for name, task in tasks:
            try:
                result = await asyncio.wait_for(task, timeout=self.diagnosis_timeout)
                results[name] = result
            except asyncio.TimeoutError:
                logger.warning(f"â±ï¸ ä»»å‹™ {name} è¶…æ™‚")
                results[name] = ToolResult(
                    success=False,
                    error=ToolError(code="TIMEOUT", message=f"ä»»å‹™ {name} åŸ·è¡Œè¶…æ™‚")
                )
        
        return results
    
    def _analyze_deployment_results(self, results: Dict[str, ToolResult], request: SRERequest) -> Dict[str, Any]:
        """åˆ†æéƒ¨ç½²è¨ºæ–·çµæœ"""
        findings = []
        issues = []
        
        # åˆ†æ Prometheus çµæœ
        if "prometheus" in results and results["prometheus"].success:
            metrics = results["prometheus"].data
            
            # æª¢æŸ¥ CPU ä½¿ç”¨ç‡
            if metrics.get("cpu_usage", "").replace("%", ""):
                cpu_usage = float(metrics["cpu_usage"].replace("%", ""))
                if cpu_usage > 80:
                    findings.append(Finding(
                        source="Prometheus",
                        severity=SeverityLevel.P1,
                        data={"cpu_usage": metrics["cpu_usage"]},
                        timestamp=datetime.now(timezone.utc)
                    ))
                    issues.append("CPU ä½¿ç”¨ç‡éé«˜")
            
            # æª¢æŸ¥è¨˜æ†¶é«”ä½¿ç”¨ç‡
            if metrics.get("memory_usage", "").replace("%", ""):
                mem_usage = float(metrics["memory_usage"].replace("%", ""))
                if mem_usage > 90:
                    findings.append(Finding(
                        source="Prometheus",
                        severity=SeverityLevel.P1,
                        data={"memory_usage": metrics["memory_usage"]},
                        timestamp=datetime.now(timezone.utc)
                    ))
                    issues.append("è¨˜æ†¶é«”ä½¿ç”¨ç‡éé«˜")
        
        # åˆ†æ Loki çµæœ
        if "loki" in results and results["loki"].success:
            logs = results["loki"].data
            if logs.get("critical_errors"):
                findings.append(Finding(
                    source="Loki",
                    severity=SeverityLevel.P0,
                    data={"errors": logs["critical_errors"]},
                    timestamp=datetime.now(timezone.utc)
                ))
                issues.extend(logs["critical_errors"])
        
        # åˆ†æå¯©è¨ˆæ—¥èªŒ
        if "audit" in results and results["audit"].success:
            audit = results["audit"].data
            if audit.get("recent_changes"):
                findings.append(Finding(
                    source="Control-Plane",
                    severity=SeverityLevel.P2,
                    data={"changes": audit["recent_changes"]},
                    timestamp=datetime.now(timezone.utc)
                ))
                issues.append("æœ€è¿‘æœ‰é…ç½®è®Šæ›´")
        
        # ç”Ÿæˆæ‘˜è¦
        if issues:
            summary = f"ç™¼ç¾ {len(issues)} å€‹å•é¡Œ: {', '.join(issues[:3])}"
            recommended_action = self._generate_recommendation(issues)
        else:
            summary = "æœªç™¼ç¾æ˜é¡¯å•é¡Œï¼Œå»ºè­°é€²ä¸€æ­¥èª¿æŸ¥"
            recommended_action = "æª¢æŸ¥æ‡‰ç”¨ç¨‹å¼æ—¥èªŒå’Œä¾è³´æœå‹™ç‹€æ…‹"
        
        return {
            "status": "COMPLETED",
            "summary": summary,
            "findings": [f.dict() for f in findings],
            "recommended_action": recommended_action,
            "confidence_score": self._calculate_confidence(findings)
        }
    
    def _generate_recommendation(self, issues: List[str]) -> str:
        """æ ¹æ“šå•é¡Œç”Ÿæˆå»ºè­°"""
        recommendations = []
        
        if "OOMKilled" in str(issues):
            recommendations.append("å¢åŠ è¨˜æ†¶é«”é™åˆ¶æˆ–å„ªåŒ–è¨˜æ†¶é«”ä½¿ç”¨")
        
        if "CPU ä½¿ç”¨ç‡éé«˜" in str(issues):
            recommendations.append("å¢åŠ  CPU é™åˆ¶æˆ–å„ªåŒ–ç¨‹å¼æ•ˆèƒ½")
        
        if "Connection timeout" in str(issues):
            recommendations.append("æª¢æŸ¥ç¶²è·¯é€£æ¥å’Œä¾è³´æœå‹™")
        
        if "æœ€è¿‘æœ‰é…ç½®è®Šæ›´" in str(issues):
            recommendations.append("å¯©æŸ¥æœ€è¿‘çš„é…ç½®è®Šæ›´")
        
        return " | ".join(recommendations) if recommendations else "é€²è¡Œæ·±å…¥è¨ºæ–·"
    
    def _calculate_confidence(self, findings: List[Finding]) -> float:
        """è¨ˆç®—è¨ºæ–·ä¿¡å¿ƒåˆ†æ•¸"""
        if not findings:
            return 0.3
        
        # æ ¹æ“šç™¼ç¾çš„åš´é‡ç¨‹åº¦è¨ˆç®—ä¿¡å¿ƒåˆ†æ•¸
        severity_scores = {
            SeverityLevel.P0: 1.0,
            SeverityLevel.P1: 0.9,
            SeverityLevel.P2: 0.7,
            SeverityLevel.P3: 0.5
        }
        
        total_score = sum(severity_scores.get(f.severity, 0.5) for f in findings)
        return min(total_score / len(findings), 1.0)