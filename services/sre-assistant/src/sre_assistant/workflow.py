# services/sre-assistant/src/sre_assistant/workflow.py
"""
SRE å·¥ä½œæµç¨‹å”èª¿å™¨ (å·²é‡æ§‹ä»¥æ”¯æ´éåŒæ­¥ä»»å‹™)
"""

import asyncio
import logging
import uuid
from typing import Dict, Any, List, Optional
from datetime import datetime, timezone

from typing import Union
from .contracts import (
    DiagnosticRequest,
    DiagnosticResult,
    DiagnosticStatus,
    ToolResult,
    ToolError,
    Finding,
    AlertAnalysisRequest,
    CapacityAnalysisRequest,
    ExecuteRequest,
    CapacityAnalysisResponse,
)

# Define a union type for all possible request models
SREWorkflowRequest = Union[DiagnosticRequest, AlertAnalysisRequest, CapacityAnalysisRequest, ExecuteRequest]
from .tools.prometheus_tool import PrometheusQueryTool
from .tools.loki_tool import LokiLogQueryTool
from .tools.control_plane_tool import ControlPlaneTool

logger = logging.getLogger(__name__)


class SREWorkflow:
    """
    ä¸»è¦çš„ SRE å·¥ä½œæµç¨‹å”èª¿å™¨
    
    è² è²¬ï¼š
    1. æ¥æ”¶è¨ºæ–·è«‹æ±‚
    2. ä¸¦è¡ŒåŸ·è¡Œå¤šå€‹è¨ºæ–·å·¥å…·
    3. æ•´åˆåˆ†æçµæœ
    4. æ›´æ–°å…±äº«çš„ä»»å‹™ç‹€æ…‹å­—å…¸
    """
    
    def __init__(self, config, redis_client):
        """åˆå§‹åŒ–å·¥ä½œæµç¨‹"""
        self.config = config
        self.redis_client = redis_client
        self.prometheus_tool = PrometheusQueryTool(config)
        self.loki_tool = LokiLogQueryTool(config)
        self.control_plane_tool = ControlPlaneTool(config)
        self.parallel_diagnosis = config.workflow.get("parallel_diagnosis", True)
        self.diagnosis_timeout = config.workflow.get("diagnosis_timeout_seconds", 120)
        logger.info("âœ… SRE å·¥ä½œæµç¨‹åˆå§‹åŒ–å®Œæˆ")
    
    async def _get_task_status(self, session_id: uuid.UUID) -> Optional[DiagnosticStatus]:
        """Helper to get task status from Redis."""
        task_json = await self.redis_client.get(str(session_id))
        if task_json:
            return DiagnosticStatus.model_validate_json(task_json)
        return None

    async def _update_task_status(self, session_id: uuid.UUID, status: DiagnosticStatus):
        """Helper to update task status in Redis."""
        await self.redis_client.set(str(session_id), status.model_dump_json(), ex=86400)

    async def execute(self, session_id: uuid.UUID, request: SREWorkflowRequest, request_type: str):
        """
        åŸ·è¡Œä¸»è¦å·¥ä½œæµç¨‹ (èƒŒæ™¯ä»»å‹™)ã€‚

        é€™æ˜¯å·¥ä½œæµç¨‹çš„æ ¸å¿ƒå…¥å£é»ï¼Œç”±èƒŒæ™¯ä»»å‹™å‘¼å«ã€‚å®ƒæœƒæ ¹æ“š `request_type`
        å°‡è«‹æ±‚è·¯ç”±åˆ°å°æ‡‰çš„è™•ç†å‡½å¼ (ä¾‹å¦‚ `_diagnose_deployment`)ã€‚

        å®ƒé‚„è² è²¬ï¼š
        - è¨˜éŒ„åŸ·è¡Œæ™‚é–“ã€‚
        - å¾ Redis ç²å–å’Œæ›´æ–°ä»»å‹™ç‹€æ…‹ã€‚
        - æ•ç²å’Œè¨˜éŒ„ä»»ä½•æœªé æœŸçš„éŒ¯èª¤ã€‚
        
        Args:
            session_id: æ­¤ä»»å‹™çš„å”¯ä¸€æœƒè©± IDã€‚
            request: SRE è«‹æ±‚ç‰©ä»¶ (ä¸€å€‹ Pydantic æ¨¡å‹)ã€‚
            request_type: è«‹æ±‚çš„é¡å‹ï¼Œç”¨æ–¼æ±ºå®šåŸ·è¡Œå“ªå€‹å­æµç¨‹ã€‚
        """
        start_time = datetime.now(timezone.utc)
        logger.info(f"ğŸš€ [Session: {session_id}] é–‹å§‹åŸ·è¡Œ {request_type} å·¥ä½œæµç¨‹...")
        
        try:
            status = await self._get_task_status(session_id)
            if not status:
                logger.error(f"ç„¡æ³•å¾ Redis ä¸­æ‰¾åˆ°ä»»å‹™ç‹€æ…‹: {session_id}")
                return

            result_data = None
            if request_type == "deployment" and isinstance(request, DiagnosticRequest):
                result_data = await self._diagnose_deployment(session_id, request, status)
            elif request_type == "alert_analysis" and isinstance(request, AlertAnalysisRequest):
                result_data = await self._diagnose_alerts(session_id, request, status)
            elif request_type == "execute_query" and isinstance(request, ExecuteRequest):
                result_data = await self._execute_query(session_id, request, status)
            elif request_type == "capacity_analysis" and isinstance(request, CapacityAnalysisRequest):
                result_data = await self._analyze_capacity(session_id, request, status)
            else:
                raise ValueError(f"æœªçŸ¥çš„è«‹æ±‚é¡å‹æˆ–è«‹æ±‚èˆ‡é¡å‹ä¸åŒ¹é…: {request_type}")

            execution_time = (datetime.now(timezone.utc) - start_time).total_seconds()
            
            final_status = await self._get_task_status(session_id)
            if final_status and isinstance(result_data, DiagnosticResult):
                final_status.result = result_data
                final_status.result.execution_time = execution_time
                final_status.status = "completed"
                final_status.progress = 100
                final_status.current_step = "è¨ºæ–·å®Œæˆ"
                await self._update_task_status(session_id, final_status)
            
            logger.info(f"âœ… [Session: {session_id}] å·¥ä½œæµç¨‹å®Œæˆ (è€—æ™‚ {execution_time:.2f}s)")
            
        except Exception as e:
            logger.error(f"âŒ [Session: {session_id}] å·¥ä½œæµç¨‹åŸ·è¡Œå¤±æ•—: {e}", exc_info=True)
            final_status = await self._get_task_status(session_id)
            if final_status:
                final_status.status = "failed"
                final_status.error = f"å·¥ä½œæµç¨‹ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}"
                await self._update_task_status(session_id, final_status)
    
    async def _diagnose_deployment(self, session_id: uuid.UUID, request: DiagnosticRequest, status: DiagnosticStatus) -> DiagnosticResult:
        """
        è¨ºæ–·éƒ¨ç½²å•é¡Œ
        """
        logger.info(f"ğŸ” [Session: {session_id}] è¨ºæ–·éƒ¨ç½²: {request.affected_services[0]}")
        
        status.current_step = "æº–å‚™è¨ºæ–·ä»»å‹™"
        status.progress = 20
        await self._update_task_status(session_id, status)
        
        tool_tasks = [
            ("prometheus", self.prometheus_tool.execute({"service": request.affected_services[0]})),
            ("loki", self.loki_tool.execute({"service": request.affected_services[0]})),
            ("audit", self.control_plane_tool.execute({"service": request.affected_services[0]}))
        ]
        
        status.current_step = "ä¸¦è¡ŒåŸ·è¡Œè¨ºæ–·å·¥å…·"
        status.progress = 50
        await self._update_task_status(session_id, status)

        results = await self._execute_parallel_tasks(tool_tasks)
        
        status.current_step = "åˆ†æè¨ºæ–·çµæœ"
        status.progress = 80
        await self._update_task_status(session_id, status)
        
        return self._analyze_deployment_results(results, request)
    
    async def _execute_parallel_tasks(self, tool_tasks: List[tuple]) -> Dict[str, ToolResult]:
        """
        ä¸¦è¡ŒåŸ·è¡Œå¤šå€‹ç•°æ­¥è¨ºæ–·å·¥å…·ä»»å‹™ï¼Œä¸¦å°æ¯å€‹ä»»å‹™å¯¦æ–½è¶…æ™‚æ§åˆ¶ã€‚

        ä½¿ç”¨ `asyncio.gather` ä¾†ä¸¦ç™¼åŸ·è¡Œæ‰€æœ‰å·¥å…·ï¼Œä¸¦é€é `return_exceptions=True`
        ç¢ºä¿å³ä½¿æŸå€‹å·¥å…·å¤±æ•—æˆ–è¶…æ™‚ï¼Œå…¶ä»–å·¥å…·ä¹Ÿèƒ½ç¹¼çºŒåŸ·è¡Œã€‚

        Args:
            tool_tasks: ä¸€å€‹åŒ…å« (åç¨±, å”ç¨‹) çš„å…ƒçµ„åˆ—è¡¨ã€‚

        Returns:
            ä¸€å€‹å­—å…¸ï¼Œéµæ˜¯å·¥å…·åç¨±ï¼Œå€¼æ˜¯å…¶ `ToolResult`ã€‚
        """
        results = {}

        tasks_with_timeout = [
            asyncio.wait_for(task, timeout=self.diagnosis_timeout) for _, task in tool_tasks
        ]

        task_results = await asyncio.gather(*tasks_with_timeout, return_exceptions=True)
        
        for i, (name, _) in enumerate(tool_tasks):
            result = task_results[i]
            if isinstance(result, asyncio.TimeoutError):
                logger.warning(f"å·¥å…· {name} åŸ·è¡Œè¶…æ™‚ (è¶…é {self.diagnosis_timeout} ç§’)")
                results[name] = ToolResult(success=False, error=ToolError(code="TOOL_TIMEOUT_ERROR", message=f"åŸ·è¡Œè¶…æ™‚ï¼Œé™åˆ¶ç‚º {self.diagnosis_timeout} ç§’"))
            elif isinstance(result, Exception):
                logger.warning(f"å·¥å…· {name} åŸ·è¡Œå¤±æ•—: {result}")
                results[name] = ToolResult(success=False, error=ToolError(code="TOOL_EXECUTION_ERROR", message=str(result)))
            else:
                results[name] = result
        return results
    
    def _analyze_deployment_results(self, results: Dict[str, ToolResult], request: DiagnosticRequest) -> DiagnosticResult:
        """åˆ†æéƒ¨ç½²è¨ºæ–·çµæœ"""
        all_findings = []
        tools_used = []
        
        if "prometheus" in results and results["prometheus"].success:
            tools_used.append("PrometheusQueryTool")
            metrics = results["prometheus"].data
            if float(metrics.get("cpu_usage", "0%").replace("%", "")) > 80:
                all_findings.append(Finding(source="Prometheus", severity="critical", message="CPU ä½¿ç”¨ç‡éé«˜", evidence=metrics))
            if float(metrics.get("memory_usage", "0%").replace("%", "")) > 90:
                all_findings.append(Finding(source="Prometheus", severity="critical", message="è¨˜æ†¶é«”ä½¿ç”¨ç‡éé«˜", evidence=metrics))

        if "loki" in results and results["loki"].success:
            tools_used.append("LokiLogQueryTool")
            logs = results["loki"].data
            if logs.get("critical_errors"):
                all_findings.append(Finding(source="Loki", severity="critical", message=f"ç™¼ç¾åš´é‡éŒ¯èª¤æ—¥èªŒ: {logs['critical_errors']}", evidence=logs))

        if "audit" in results and results["audit"].success:
            tools_used.append("ControlPlaneTool")
            audit = results["audit"].data
            if audit.get("recent_changes"):
                all_findings.append(Finding(source="Control-Plane", severity="warning", message=f"ç™¼ç¾æœ€è¿‘æœ‰é…ç½®è®Šæ›´", evidence=audit))

        if all_findings:
            summary = f"è¨ºæ–·å®Œæˆï¼Œå…±ç™¼ç¾ {len(all_findings)} å€‹å•é¡Œé»ã€‚"
            recommended_actions = ["è«‹æ ¹æ“šç™¼ç¾çš„è©³ç´°è³‡è¨Šé€²è¡Œæ·±å…¥èª¿æŸ¥ã€‚"]
            confidence_score = 0.8
        else:
            summary = "åˆæ­¥è¨ºæ–·æœªç™¼ç¾æ˜é¡¯å•é¡Œã€‚"
            recommended_actions = ["å»ºè­°æ‰‹å‹•æª¢æŸ¥æœå‹™æ—¥èªŒå’Œç›£æ§å„€è¡¨æ¿ã€‚"]
            confidence_score = 0.5
            
        return DiagnosticResult(
            summary=summary,
            findings=all_findings,
            recommended_actions=recommended_actions,
            confidence_score=confidence_score,
            tools_used=tools_used
        )

    async def _diagnose_alerts(self, session_id: uuid.UUID, request: AlertAnalysisRequest, status: DiagnosticStatus) -> DiagnosticResult:
        """
        è¨ºæ–·å‘Šè­¦å•é¡Œ (éª¨æ¶)
        """
        logger.info(f"ğŸ” [Session: {session_id}] è¨ºæ–·å‘Šè­¦: {request.alert_ids}")
        status.current_step = "åˆ†æå‘Šè­¦é—œè¯æ€§"
        status.progress = 50
        await self._update_task_status(session_id, status)
        await asyncio.sleep(2) # æ¨¡æ“¬å·¥ä½œ

        status.current_step = "ç”Ÿæˆå‘Šè­¦è¨ºæ–·å ±å‘Š"
        status.progress = 90
        await self._update_task_status(session_id, status)
        return DiagnosticResult(summary=f"å·²åˆ†æ {len(request.alert_ids)} å€‹å‘Šè­¦ã€‚", findings=[], recommended_actions=["æª¢æŸ¥é—œè¯æœå‹™çš„æ—¥èªŒ"])

    async def _analyze_capacity(self, session_id: uuid.UUID, request: CapacityAnalysisRequest, status: DiagnosticStatus) -> CapacityAnalysisResponse:
        """
        åˆ†æå®¹é‡å•é¡Œ (éª¨æ¶)
        """
        logger.info(f"ğŸ“ˆ [Session: {session_id}] åˆ†æå®¹é‡: {request.resource_ids}")
        return CapacityAnalysisResponse(
            current_usage={"average": 55.5, "peak": 80.2},
            forecast={"trend": "increasing", "days_to_capacity": 45},
            recommendations=[{"type": "scale_up", "resource": request.resource_ids[0], "priority": "high", "reasoning": "é æ¸¬ä½¿ç”¨é‡å°‡åœ¨ 45 å¤©å¾Œé”åˆ°ç“¶é ¸"}]
        )

    async def _execute_query(self, session_id: uuid.UUID, request: ExecuteRequest, status: DiagnosticStatus) -> DiagnosticResult:
        """
        åŸ·è¡Œè‡ªç„¶èªè¨€æŸ¥è©¢ (éª¨æ¶)
        """
        logger.info(f"ğŸ¤– [Session: {session_id}] åŸ·è¡ŒæŸ¥è©¢: {request.query}")
        status.current_step = "è§£æè‡ªç„¶èªè¨€æŸ¥è©¢"
        status.progress = 30
        await self._update_task_status(session_id, status)
        await asyncio.sleep(1)

        status.current_step = "åŸ·è¡Œå°æ‡‰çš„å·¥å…·"
        status.progress = 70
        await self._update_task_status(session_id, status)
        await asyncio.sleep(2)
        return DiagnosticResult(summary=f"å·²åŸ·è¡ŒæŸ¥è©¢: '{request.query}'", findings=[], recommended_actions=["ç„¡"])