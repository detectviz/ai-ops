# services/sre-assistant/src/sre_assistant/main.py
"""
SRE Assistant ä¸»ç¨‹å¼å…¥å£
æä¾› REST API ç«¯é»ä¾› Control Plane å‘¼å« (å·²é‡æ§‹ç‚ºéåŒæ­¥)
"""

from fastapi import FastAPI, HTTPException, Depends, Request, BackgroundTasks, Response
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
from datetime import datetime, timezone, timedelta
import os
import logging
import uuid
from typing import Dict, Any, Optional, List
import redis.asyncio as redis
from jose import jwt, jwk
from jose.exceptions import JOSEError
import httpx
import time

from .contracts import (
    DiagnosticRequest,
    DiagnosticResponse,
    DiagnosticStatus,
    AlertAnalysisRequest,
    CapacityAnalysisRequest,
    CapacityAnalysisResponse,
    ExecuteRequest,
    DiagnosticHistoryList,
    DiagnosticHistoryItem,
    WorkflowTemplate,
    ToolStatus,
    Pagination,
)
from .workflow import SREWorkflow, SREWorkflowRequest
from .config.config_manager import ConfigManager

# --- çµæ§‹åŒ–æ—¥èªŒè¨­å®š ---
import structlog
import contextvars

# 1. ç‚ºè«‹æ±‚ ID å»ºç«‹ ContextVar
request_id_var = contextvars.ContextVar("request_id", default=None)

def configure_logging():
    """è¨­å®š structlog ä»¥è¼¸å‡º JSON æ ¼å¼çš„æ—¥èªŒ"""

    # structlog è™•ç†å™¨éˆ
    processors = [
        # å°‡ contextvars (å¦‚ request_id) åˆä½µåˆ°æ—¥èªŒè¨˜éŒ„ä¸­
        structlog.contextvars.merge_contextvars,
        # æ–°å¢æ—¥èªŒç´šåˆ¥å’Œåç¨±ç­‰æ¨™æº–å±¬æ€§
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        # æ–°å¢æ™‚é–“æˆ³
        structlog.processors.TimeStamper(fmt="iso"),
        # å¦‚æœæœ‰ç•°å¸¸ï¼Œæ ¼å¼åŒ–å®ƒ
        structlog.processors.format_exc_info,
        # æ¸²æŸ“ç‚º JSON
        structlog.processors.JSONRenderer(),
    ]

    structlog.configure(
        processors=processors,
        logger_factory=structlog.stdlib.LoggerFactory(),
        wrapper_class=structlog.stdlib.BoundLogger,
        cache_logger_on_first_use=True,
    )

# åœ¨æ‡‰ç”¨å•Ÿå‹•æ™‚è¨­å®šæ—¥èªŒ
configure_logging()
logger = structlog.get_logger(__name__)
# --- çµæ§‹åŒ–æ—¥èªŒè¨­å®šçµæŸ ---

# å…¨åŸŸè®Šæ•¸
config_manager: Optional[ConfigManager] = None
workflow: Optional[SREWorkflow] = None
redis_client: Optional[redis.Redis] = None
app_ready = False

@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    æ‡‰ç”¨ç¨‹å¼ç”Ÿå‘½é€±æœŸç®¡ç† (Application Lifespan Management)ã€‚

    é€™å€‹ç•°æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨æœƒåœ¨ FastAPI æ‡‰ç”¨å•Ÿå‹•æ™‚åŸ·è¡Œ `try` å€å¡Šä¸­çš„ç¨‹å¼ç¢¼ï¼Œ
    ä¸¦åœ¨æ‡‰ç”¨é—œé–‰æ™‚åŸ·è¡Œ `finally` å€å¡Šä¸­çš„ç¨‹å¼ç¢¼ã€‚
    é€™å°æ–¼åˆå§‹åŒ–å’Œæ¸…ç†è³‡æº (å¦‚è³‡æ–™åº«é€£æ¥ã€èƒŒæ™¯ä»»å‹™) éå¸¸æœ‰ç”¨ã€‚
    """
    global config_manager, workflow, redis_client, app_ready
    
    logger.info("ğŸš€ æ­£åœ¨å•Ÿå‹• SRE Assistant...")
    
    try:
        config_manager = ConfigManager()
        config = config_manager.get_config()

        # åˆå§‹åŒ– Redis Client
        redis_client = redis.from_url(
            config.redis.url,
            encoding="utf-8",
            decode_responses=True
        )
        await redis_client.ping()
        logger.info("âœ… å·²æˆåŠŸé€£æ¥åˆ° Redis")

        # åˆå§‹åŒ–å·¥ä½œæµç¨‹å¼•æ“ï¼Œä¸¦å‚³å…¥ Redis client
        workflow = SREWorkflow(config, redis_client)

        app_ready = True
        logger.info("âœ… å·¥ä½œæµç¨‹å¼•æ“èˆ‡ä»»å‹™å„²å­˜å·²åˆå§‹åŒ–")

        logger.info("âœ… SRE Assistant å•Ÿå‹•å®Œæˆ")
        yield
    except Exception as e:
        logger.error(f"ğŸ’€ SRE Assistant å•Ÿå‹•å¤±æ•—: {e}", exc_info=True)
        app_ready = False
        yield # Still yield to allow the app to run and report not ready
    finally:
        if redis_client:
            await redis_client.close()
            logger.info("Redis é€£ç·šå·²é—œé–‰")
        logger.info("ğŸ›‘ æ­£åœ¨é—œé–‰ SRE Assistant...")
        app_ready = False


app = FastAPI(
    title="SRE Platform API",
    version="1.0.0",
    description="SRE Platform çš„éåŒæ­¥è¨ºæ–·èˆ‡åˆ†æå¼•æ“",
    lifespan=lifespan
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- Request ID ä¸­ä»‹å±¤ ---
@app.middleware("http")
async def request_id_middleware(request: Request, call_next):
    """
    æ””æˆªè«‹æ±‚ï¼Œç”Ÿæˆå”¯ä¸€çš„ request_idï¼Œä¸¦å°‡å…¶æ”¾å…¥ context varã€‚
    """
    request_id = request.headers.get("X-Request-ID", str(uuid.uuid4()))
    request_id_var.set(request_id)
    response = await call_next(request)
    response.headers["X-Request-ID"] = request_id
    return response

security = HTTPBearer()

# --- JWT é©—è­‰é‚è¼¯ ---

# JWKS (JSON Web Key Set) çš„è¨˜æ†¶é«”å¿«å–ã€‚
# ç‚ºäº†é¿å…æ¯æ¬¡é©—è­‰ token éƒ½éœ€è¦å‘ Keycloak è«‹æ±‚å…¬é‘°ï¼Œæˆ‘å€‘å°‡å…¬é‘°é›†å¿«å–åœ¨è¨˜æ†¶é«”ä¸­ã€‚
# ttl (Time-To-Live) è¨­å®šç‚ºä¸€å°æ™‚ï¼ŒéæœŸå¾Œæœƒé‡æ–°ç²å–ã€‚
jwks_cache = {
    "keys": None,
    "last_updated": 0,
    "ttl": 3600
}

async def fetch_jwks(jwks_url: str) -> List[Dict[str, Any]]:
    """
    å¾ Keycloak çš„ JWKS ç«¯é»ç²å–å…¬é‘°é›†ã€‚

    å¯¦ç¾äº†ç°¡å–®çš„æ™‚é–“å¿«å–æ©Ÿåˆ¶ï¼Œä»¥é™ä½å° Keycloak çš„è«‹æ±‚é »ç‡ã€‚

    Args:
        jwks_url: Keycloak çš„ JWKS ç«¯é» URLã€‚

    Returns:
        ä¸€å€‹åŒ…å«å¤šå€‹å…¬é‘°çš„åˆ—è¡¨ã€‚
    """
    now = time.time()
    if jwks_cache["keys"] and (now - jwks_cache["last_updated"] < jwks_cache["ttl"]):
        return jwks_cache["keys"]

    async with httpx.AsyncClient() as client:
        try:
            response = await client.get(jwks_url)
            response.raise_for_status()
            jwks = response.json()
            jwks_cache["keys"] = jwks.get("keys", [])
            jwks_cache["last_updated"] = now
            logger.info("âœ… æˆåŠŸç²å–ä¸¦å¿«å– JWKS")
            return jwks_cache["keys"]
        except httpx.HTTPStatusError as e:
            logger.error(f"å¾ Keycloak ç²å– JWKS å¤±æ•—: {e}")
            raise HTTPException(status_code=500, detail="ç„¡æ³•ç²å–èªè­‰é‡‘é‘°")
        except Exception as e:
            logger.error(f"è™•ç† JWKS æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {e}")
            raise HTTPException(status_code=500, detail="èªè­‰æœå‹™å…§éƒ¨éŒ¯èª¤")


async def verify_token(creds: HTTPAuthorizationCredentials = Depends(security)) -> Dict[str, Any]:
    """
    é©—è­‰ä¾†è‡ª Control Plane çš„ M2M JWT Tokenã€‚

    é€™æ˜¯ä¸€å€‹ FastAPI çš„ä¾è³´é … (Dependency)ï¼Œæœƒè¢«æ³¨å…¥åˆ°éœ€è¦ä¿è­·çš„ API ç«¯é»ä¸­ã€‚
    å®ƒæœƒåŸ·è¡Œä»¥ä¸‹æ­¥é©Ÿï¼š
    1. æª¢æŸ¥è¨­å®šæª”ï¼Œå¦‚æœ auth provider ä¸æ˜¯ keycloakï¼Œå‰‡è·³éé©—è­‰ã€‚
    2. å¾ HTTP Authorization æ¨™é ­ä¸­æå– Bearer Tokenã€‚
    3. ç²å– Keycloak çš„ JWKS å…¬é‘°é›†ã€‚
    4. å¾ Token çš„æ¨™é ­ä¸­è§£æå‡º `kid` (Key ID)ã€‚
    5. åœ¨ JWKS ä¸­å°‹æ‰¾èˆ‡ `kid` åŒ¹é…çš„å…¬é‘°ã€‚
    6. ä½¿ç”¨å…¬é‘°é©—è­‰ Token çš„ç°½åã€ç™¼è¡Œè€… (issuer)ã€å—çœ¾ (audience) å’ŒéæœŸæ™‚é–“ã€‚
    7. å¦‚æœé©—è­‰æˆåŠŸï¼Œè¿”å›è§£ç¢¼å¾Œçš„ Token payloadï¼›å¦å‰‡ï¼Œæ‹‹å‡º HTTPExceptionã€‚
    """
    config = config_manager.get_config()
    logger.info(f"[DEBUG] In verify_token, auth provider is: '{config.auth.provider}'")
    if config.auth.provider != "keycloak":
        logger.warning("Auth provider ä¸æ˜¯ keycloakï¼Œè·³é JWT é©—è­‰")
        return {"sub": "service-account-control-plane"}

    logger.info("âœ… Keycloak èªè­‰æœå‹™å·²åˆå§‹åŒ– (Python)")
    token = creds.credentials
    try:
        keycloak_url = config.auth.keycloak.url
        realm = config.auth.keycloak.realm
        audience = config.auth.keycloak.audience

        jwks_url = f"{keycloak_url}/realms/{realm}/protocol/openid-connect/certs"

        jwks_keys = await fetch_jwks(jwks_url)
        if not jwks_keys:
            raise HTTPException(status_code=503, detail="ç„¡æ³•åŠ è¼‰èªè­‰æœå‹™å…¬é‘°")

        unverified_header = jwt.get_unverified_header(token)
        kid = unverified_header.get("kid")
        if not kid:
            raise HTTPException(status_code=401, detail="Token æ¨™é ­ä¸­ç¼ºå°‘ 'kid'")

        rsa_key = {}
        for key in jwks_keys:
            if key["kid"] == kid:
                rsa_key = {
                    "kty": key["kty"],
                    "kid": key["kid"],
                    "use": key["use"],
                    "n": key["n"],
                    "e": key.get("e"), # 'e' is optional for some key types
                }
                break

        if not rsa_key:
            raise HTTPException(status_code=401, detail="æ‰¾ä¸åˆ°å°æ‡‰çš„å…¬é‘°")

        public_key = jwk.construct(rsa_key)

        payload = jwt.decode(
            token,
            public_key,
            algorithms=["RS256"],
            audience=audience,
            issuer=f"{keycloak_url}/realms/{realm}"
        )
        return payload

    except jwt.ExpiredSignatureError:
        raise HTTPException(status_code=401, detail="Token å·²éæœŸ")
    except jwt.JWTClaimsError as e:
        raise HTTPException(status_code=401, detail=f"Token claims éŒ¯èª¤: {e}")
    except JOSEError as e:
        logger.error(f"JWT è§£ç¢¼/é©—è­‰éŒ¯èª¤: {e}", exc_info=True)
        raise HTTPException(status_code=401, detail=f"ç„¡æ•ˆçš„ Token: {e}")
    except Exception as e:
        logger.error(f"æœªçŸ¥çš„ Token é©—è­‰éŒ¯èª¤: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Token é©—è­‰æ™‚ç™¼ç”Ÿå…§éƒ¨éŒ¯èª¤")


# === èƒŒæ™¯ä»»å‹™åŸ·è¡Œå™¨ ===
async def run_workflow_bg(session_id: uuid.UUID, request: SREWorkflowRequest, request_type: str):
    """
    ä¸€å€‹é€šç”¨çš„åŒ…è£å‡½å¼ï¼Œç”¨æ–¼åœ¨èƒŒæ™¯åŸ·è¡Œå·¥ä½œæµç¨‹ä¸¦æ›´æ–°ä»»å‹™ç‹€æ…‹ã€‚

    Args:
        session_id: æ­¤æ¬¡ä»»å‹™çš„å”¯ä¸€æœƒè©± IDã€‚
        request: API è«‹æ±‚çš„è³‡æ–™æ¨¡å‹ã€‚
        request_type: è«‹æ±‚çš„é¡å‹ï¼Œç”¨æ–¼åœ¨å·¥ä½œæµç¨‹ä¸­é€²è¡Œè·¯ç”±ã€‚
    """
    initial_status = DiagnosticStatus(
        session_id=session_id,
        status="processing",
        progress=10,
        current_step=f"é–‹å§‹åŸ·è¡Œ {request_type} å·¥ä½œæµç¨‹"
    )
    # å°‡åˆå§‹ç‹€æ…‹å¯«å…¥ Redisï¼Œè¨­å®š 24 å°æ™‚éæœŸ
    await redis_client.set(
        str(session_id),
        initial_status.model_dump_json(),
        ex=86400
    )
    await workflow.execute(session_id, request, request_type)


# === API ç«¯é» ===

@app.get("/api/v1/healthz", tags=["Health"])
def check_liveness():
    """
    å¥åº·æª¢æŸ¥ç«¯é» - é©—è­‰æœå‹™æ˜¯å¦æ­£å¸¸é‹è¡Œ
    è¿”å› HealthStatus çµæ§‹ï¼Œç¬¦åˆ OpenAPI è¦ç¯„
    """
    from datetime import datetime
    import time

    # è¨ˆç®—é‹è¡Œæ™‚é–“ï¼ˆå¾æ‡‰ç”¨å•Ÿå‹•è‡³ä»Šï¼‰
    uptime = int(time.time() - startup_time) if 'startup_time' in globals() else 0

    return {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat() + "Z",
        "version": "1.0.0",
        "uptime": uptime
    }

from prometheus_client import generate_latest, CONTENT_TYPE_LATEST

@app.get("/api/v1/readyz", tags=["Health"])
async def check_readiness(response: Response):
    """
    åŸ·è¡Œæ·±å…¥çš„å°±ç·’æª¢æŸ¥ï¼Œé©—è­‰æ‰€æœ‰å¾Œç«¯ä¾è³´æ˜¯å¦å¯ç”¨ã€‚
    """
    checks = {
        "redis": False,
        "prometheus": False,
        "loki": False,
        "control_plane": False
    }

    if not app_ready or not workflow or not redis_client:
        response.status_code = 503
        return {
            "ready": False,
            "checks": checks
        }

    try:
        # é©—è­‰èˆ‡ Redis çš„å³æ™‚é€£ç·š
        await redis_client.ping()
        checks["redis"] = True

        # é€™è£¡å¯ä»¥åŠ å…¥å…¶ä»–ä¾è³´æª¢æŸ¥
        # TODO: æª¢æŸ¥èˆ‡ Prometheus çš„é€£ç·š
        # TODO: æª¢æŸ¥èˆ‡ Loki çš„é€£ç·š
        # TODO: æª¢æŸ¥èˆ‡ Control Plane çš„é€£ç·š

        # ç›®å‰åªæª¢æŸ¥ Redisï¼Œæ‰€ä»¥å…¶ä»–æª¢æŸ¥è¨­ç‚º Trueï¼ˆè¡¨ç¤ºä¸é€²è¡Œæª¢æŸ¥ï¼‰
        checks["prometheus"] = True
        checks["loki"] = True
        checks["control_plane"] = True

        return {
            "ready": all(checks.values()),
            "checks": checks
        }
    except redis.exceptions.ConnectionError as e:
        logger.error(f"Redis é€£ç·šæª¢æŸ¥å¤±æ•—: {e}", exc_info=True)
        response.status_code = 503
        return {
            "ready": False,
            "checks": checks
        }
    except Exception as e:
        logger.error(f"å°±ç·’æª¢æŸ¥æ™‚ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤: {e}", exc_info=True)
        response.status_code = 503
        return {
            "ready": False,
            "checks": checks
        }

@app.get("/api/v1/metrics", tags=["Health"])
def get_metrics():
    """æä¾› Prometheus æ ¼å¼çš„æŒ‡æ¨™"""
    return Response(content=generate_latest(), media_type=CONTENT_TYPE_LATEST)

@app.post("/api/v1/diagnostics/deployment", tags=["Diagnostics"], status_code=202, response_model=DiagnosticResponse)
async def diagnose_deployment(
    request: DiagnosticRequest,
    background_tasks: BackgroundTasks,
    token: Dict[str, Any] = Depends(verify_token)
):
    """
    æ¥æ”¶éƒ¨ç½²è¨ºæ–·è«‹æ±‚ï¼Œä¸¦éåŒæ­¥è™•ç†ã€‚
    """
    session_id = uuid.uuid4()
    background_tasks.add_task(run_workflow_bg, session_id, request, "deployment")
    
    return DiagnosticResponse(
        session_id=session_id,
        status="accepted",
        message="éƒ¨ç½²è¨ºæ–·ä»»å‹™å·²æ¥å—ï¼Œæ­£åœ¨èƒŒæ™¯è™•ç†ä¸­ã€‚",
        estimated_time=120
    )

@app.get("/api/v1/diagnostics/{sessionId}/status", tags=["Diagnostics"], response_model=DiagnosticStatus)
async def get_diagnostic_status(
    sessionId: uuid.UUID,
    token: Dict[str, Any] = Depends(verify_token)
):
    """
    æŸ¥è©¢éåŒæ­¥è¨ºæ–·ä»»å‹™çš„ç‹€æ…‹ã€‚
    """
    task_json = await redis_client.get(str(sessionId))
    if not task_json:
        raise HTTPException(status_code=404, detail="æ‰¾ä¸åˆ°æŒ‡å®šçš„è¨ºæ–·ä»»å‹™")

    return DiagnosticStatus.model_validate_json(task_json)

# --- New Endpoints ---

@app.post("/api/v1/diagnostics/alerts", tags=["Diagnostics"], status_code=202, response_model=DiagnosticResponse)
async def analyze_alerts(
    request: AlertAnalysisRequest,
    background_tasks: BackgroundTasks,
    token: Dict[str, Any] = Depends(verify_token)
):
    """
    æ¥æ”¶å‘Šè­¦åˆ†æè«‹æ±‚ï¼Œä¸¦éåŒæ­¥è™•ç†ã€‚
    """
    session_id = uuid.uuid4()
    background_tasks.add_task(run_workflow_bg, session_id, request, "alert_analysis")

    return DiagnosticResponse(
        session_id=session_id,
        status="accepted",
        message="å‘Šè­¦åˆ†æä»»å‹™å·²æ¥å—ï¼Œæ­£åœ¨èƒŒæ™¯è™•ç†ä¸­ã€‚",
        estimated_time=60
    )

@app.post("/api/v1/diagnostics/capacity", tags=["Diagnostics"], status_code=200, response_model=CapacityAnalysisResponse)
async def analyze_capacity(
    request: CapacityAnalysisRequest,
    token: Dict[str, Any] = Depends(verify_token)
):
    """
    æ¥æ”¶å®¹é‡åˆ†æè«‹æ±‚ï¼Œä¸¦åŒæ­¥è™•ç†ã€‚
    """
    # é€™æ˜¯åŒæ­¥ç«¯é»çš„éª¨æ¶ï¼Œç›®å‰è¿”å›æ¨¡æ“¬æ•¸æ“š
    # å¯¦éš›é‚è¼¯å°‡åœ¨ workflow.py ä¸­å¯¦ç¾
    logger.info(f"æ¥æ”¶åˆ°å®¹é‡åˆ†æè«‹æ±‚: {request.resource_ids}")
    # TODO: å‘¼å« workflow ä¸­çš„åŒæ­¥æ–¹æ³•
    return CapacityAnalysisResponse(
        current_usage={"average": 55.5, "peak": 80.2},
        forecast={"trend": "increasing", "days_to_capacity": 45},
        recommendations=[{"type": "scale_up", "resource": request.resource_ids[0], "priority": "high", "reasoning": "é æ¸¬ä½¿ç”¨é‡å°‡åœ¨ 45 å¤©å¾Œé”åˆ°ç“¶é ¸"}]
    )

@app.post("/api/v1/execute", tags=["Diagnostics"], status_code=202, response_model=DiagnosticResponse)
async def execute_query(
    request: ExecuteRequest,
    background_tasks: BackgroundTasks,
    token: Dict[str, Any] = Depends(verify_token)
):
    """
    æ¥æ”¶è‡ªç„¶èªè¨€æŸ¥è©¢è«‹æ±‚ï¼Œä¸¦éåŒæ­¥è™•ç†ã€‚
    """
    session_id = uuid.uuid4()
    background_tasks.add_task(run_workflow_bg, session_id, request, "execute_query")

    return DiagnosticResponse(
        session_id=session_id,
        status="accepted",
        message="è‡ªç„¶èªè¨€æŸ¥è©¢ä»»å‹™å·²æ¥å—ï¼Œæ­£åœ¨èƒŒæ™¯è™•ç†ä¸­ã€‚",
        estimated_time=180
    )

@app.get("/api/v1/diagnostics/history", tags=["Diagnostics"], response_model=DiagnosticHistoryList)
async def get_diagnostic_history(
    page: int = 1,
    page_size: int = 20,
    token: Dict[str, Any] = Depends(verify_token)
):
    """
    æŸ¥è©¢æ­·å²è¨ºæ–·è¨˜éŒ„ (éª¨æ¶)ã€‚
    """
    # æ¨¡æ“¬æ•¸æ“š
    items = [
        DiagnosticHistoryItem(
            session_id=uuid.uuid4(),
            incident_id="INC-2025-001",
            status="completed",
            created_at=datetime.now(timezone.utc) - timedelta(hours=1),
            completed_at=datetime.now(timezone.utc) - timedelta(minutes=50),
            summary="åˆæ­¥è¨ºæ–·æœªç™¼ç¾æ˜é¡¯å•é¡Œã€‚"
        )
    ]
    return DiagnosticHistoryList(
        items=items,
        pagination=Pagination(page=page, page_size=page_size, total=len(items), total_pages=1)
    )

@app.get("/api/v1/workflows/templates", tags=["Workflows"], response_model=List[WorkflowTemplate])
async def list_workflow_templates(token: Dict[str, Any] = Depends(verify_token)):
    """
    ç²å–å·¥ä½œæµæ¨¡æ¿ (éª¨æ¶)ã€‚
    """
    # æ¨¡æ“¬æ•¸æ“š
    templates = [
        WorkflowTemplate(id="deployment_diagnosis", name="éƒ¨ç½²å•é¡Œè¨ºæ–·", description="åˆ†æéƒ¨ç½²å¤±æ•—æˆ–æ‡‰ç”¨ç¨‹å¼å•Ÿå‹•ç•°å¸¸å•é¡Œã€‚", parameters=[]),
        WorkflowTemplate(id="alert_correlation", name="å‘Šè­¦é—œè¯åˆ†æ", description="åˆ†æå¤šå€‹å‘Šè­¦ä¹‹é–“çš„é—œè¯æ€§ï¼Œå°‹æ‰¾æ ¹æœ¬åŸå› ã€‚", parameters=[{"name": "alert_ids", "type": "list"}]),
    ]
    return templates

@app.get("/api/v1/tools/status", tags=["Tools"], response_model=Dict[str, ToolStatus])
async def get_tools_status(token: Dict[str, Any] = Depends(verify_token)):
    """
    ç²å–å·¥å…·ç‹€æ…‹ (éª¨æ¶)ã€‚
    """
    # æ¨¡æ“¬æ•¸æ“š
    now = datetime.now(timezone.utc)
    return {
        "prometheus": ToolStatus(status="healthy", last_checked=now),
        "loki": ToolStatus(status="healthy", last_checked=now),
        "control_plane": ToolStatus(status="unhealthy", last_checked=now, details={"error": "Connection timeout"})
    }